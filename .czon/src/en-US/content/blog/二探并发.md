---
"title": "A Second Look at Concurrency (Actor)"
"summary": "This article first analyzes the issues that arise when using a shared message queue in concurrent systems where workers need to perform specialized tasks asynchronously: messages cannot be directed to specific workers, misdelivered messages lead to inefficiency, and timing problems occur. The author points out the FIFO nature of shared message queues and the efficiency issues introduced by locking mechanisms, then proposes the Actor model as a fundamental solution. The Actor model addresses this by assigning each worker its own independent message queue (mailbox), enabling directed asynchronous communication and avoiding the complexities of shared memory. The article explains the concepts of the Actor model in detail and provides a sample implementation in Python using threads, demonstrating how to implement basic Actor functionality—sending messages, receiving messages, and thread management—through a BaseWorker class. Finally, the author concludes that concurrent programming requires a more abstract way of thinking, and the Actor model serves as a helpful guide for getting started."
"tags":
  - "python"
  - "concurrency"
  - "Actor model"
  - "message queue"
  - "asynchronous programming"
"date": "2017-05-19"
---

---
title: A Second Look at Concurrency (Actor)
date: 2017-05-19
taxonomies:
  tags:
    - python
    - concurrency
---

[Last time](http://0xc1.space/2017/05/06/初探并发/), we discussed using message queues to pass messages between threads (or processes) to achieve inter-thread communication.

<!--more-->

## The Shared Message Queue

This approach is based on the assumption that **concurrency is solely for improving system throughput**. Under this assumption, every worker performs the same type of work, so they can share a single message queue—it doesn't matter which worker picks up the next instruction.

### What if We Are Not Siblings?

What if we need to implement a system where each worker has a specialized role and works asynchronously (for example, our IP-phone)? Suppose we still use the method above, with all workers sharing a single message queue. A problem arises: messages cannot be sent to specific workers.

How can we solve this? A simple and crude solution is to add an identifier to each message, indicating its intended recipient:

```python
queue = Queue([('Send_to_worker_A', 'do_something1'),
               ('Send_to_worker_B', 'do_something2'),
               ('Send_to_worker_B', 'do_something3'),
               ('Send_to_worker_C', 'do_something4'),
               ('Send_to_worker_A', 'do_something5')])
```

It seems the problem is solved, right? But we've introduced a new issue.

### What if I Accidentally Open Someone Else's Mail?

If a message intended for worker A is received by worker B, it's essentially useless to worker B. Meanwhile, worker A, who should have received it, doesn't get the message, causing it to be lost. This wastes worker B's time, consumes worker A's waiting time, and could even lead the entire system into some bizarre bug due to a skipped step.

How do we solve this problem? Intuitively, adding the following strategy to each worker seems to fix it: if a worker receives a message meant for someone else, put it back into the message queue.

```python
class Worker_B:
    
    def run(self):
        while True:
            if not self.queue.empty():
                data = self.queue.get()
                if data['to_whom'] == 'worker_B':
                    do_something_with_data
                else:
                    self.queue.put(data)
```

It seems like patching fixes the problem... but in reality, it introduces yet another issue.

### This Looks Like a Dead End

First, a message queue is a queue, meaning FIFO (First-In-First-Out). Even if we introduce a priority queue, this fundamental characteristic doesn't change. Therefore, a message that should have been delivered first to worker A, after being handled by worker B, becomes the last message in the queue for worker A. This could lead the system into strange bugs.

Second, even if we manage to reinsert a misdelivered message at the front of the queue, without introducing a locking mechanism to make worker B's `receive-check-return` operation atomic, other workers might continue receiving messages while worker B is performing the return operation. This could still cause significant timing issues. While introducing locks can solve logical errors, it would result in only one worker being able to work effectively during each polling cycle. Other workers that receive wrong messages and perform the `receive-check-return` operation would waste their time slices, leading to **inefficiency**.

Therefore, for a system that introduces concurrency for asynchronous work, having all workers share a single message queue doesn't seem like a good approach.

The fundamental solution to this problem is to create a dedicated message queue (mailbox) for each group of workers performing the same task, or even assign each worker its own message queue, completely abandoning the ability to share memory between threads. The latter approach is the protagonist of today's discussion: **the Actor model (Participant pattern)**.

## The Actor Model

First, let's look at the definition and concepts of the Actor model from Wikipedia:

### Concepts

In computer science, the Actor model is a mathematical model of concurrent computation. An "actor" is a fundamental unit of computation: in response to a message it receives, an actor can make local decisions, create more actors, send more messages, and determine how to respond to the next message received. The Actor model was introduced in 1973 by Carl Hewitt, Peter Bishop, and Richard Steiger.

The philosophy promoted by the Actor model is "everything is an actor," similar to the object-oriented programming mantra "everything is an object." However, object-oriented programming is typically sequential, while the Actor model is inherently parallel. An actor is a computational entity that, in response to messages it receives, can concurrently:

- Send a finite number of messages to other actors;
- Create a finite number of new actors;
- Designate the behavior to be used for the next message it receives.

These actions do not assume sequential execution and can thus be performed in parallel. The decoupling of the sender from the sent message is a fundamental advantage of the Actor model. This enables asynchronous communication while satisfying the control structures of message passing. Message recipients are distinguished by addresses, sometimes called "mailing addresses." Therefore, an actor can only communicate with actors whose addresses it possesses. It can obtain addresses from received messages or from actors it creates. Key characteristics of the Actor model include: parallel computation within or between actors, dynamic creation of actors, addresses included in messages, interaction solely through direct asynchronous message passing, and no constraints on message arrival order.

### Implementation

Actors are simple, born for concurrency, and offer sufficient encapsulation to isolate changes (e.g., not caring whether it's multithreaded or multiprocess).

Let's look at a typical Python thread-based implementation of an Actor:

```python
from queue import Queue
from threading import Thread, Event


class WorkerExit(Exception):
    # Exception used to terminate the task
    pass


class BaseWorker(object):
    # Actor
    def __init__(self):
        self._mailbox = Queue()
        super(BaseWorker, self).__init__()

    def send(self, msg):
        self._mailbox.put(msg)

    def recv(self):
        msg = self._mailbox.get()
        if msg is WorkerExit:
            raise WorkerExit()
        return msg

    def close(self):
        self.send(WorkerExit)

    def start(self):
        self._terminated = Event()
        t = Thread(target=self._bootstrap)

        t.daemon = True
        t.start()

    def _bootstrap(self):
        try:
            self.run()
        except WorkerExit:
            pass
        finally:
            self._terminated.set()

    def join(self):
        self._terminated.wait()

    def run(self):
        raise NotImplementedError
```

To briefly explain, this Actor (which I've named `BaseWorker` and used as a parent class in real projects) maintains two data structures: a `Queue` as the mailbox and an `Event` as a mechanism to block the main thread.

The core operation exposed as an external interface here is the `send()` method. Note that **we do not restrict the type of messages that can be passed**, which offers immense flexibility.

Inside the Actor, we use a thread to run the `run()` method, combined with the `recv()` method, to perform the specified tasks. It's worth mentioning that we set a sentinel signal, `WorkerExit`, to stop tasks. Note how `WorkerExit` works: when recognized, it is raised as an exception. In the exception handling, we could do even more, though here we simply stop the thread when this exception is caught. This exception handling is implemented via the `_bootstrap()` method, which wraps `run()`.

Following the philosophy of the Actor model, we can extend this simple example to go much further.

## Conclusion

Concurrent programming requires a more abstract way of thinking than usual and serves as good practice for the principle of "high cohesion, low coupling."

In my exploration of this entirely new field, the Actor model has indeed been a guiding light, leading me to truly get started. Hence, I share it here. :)