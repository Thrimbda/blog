---
"title": "K8s 単一ノードクラスタ上での Prometheus 手動構築"
"summary": "本記事は、Kubernetes 単一ノードクラスタ上で Prometheus 監視システムを手動で構築する詳細なガイドです。まず、構築環境として K8s バージョン 1.19.3 と Prometheus バージョン 2.22.0 を紹介し、Helm-Chart や Prometheus Operator などの簡易デプロイ方法を使用せず、手動で YAML 設定ファイルを作成する方針を明確にしています。内容は概念検証とクラスタ監視の2部構成です：概念検証フェーズでは、ベアメタル上で Prometheus と Node Exporter を実行し、設定ファイルを修正して自身とノードのメトリクスを監視するデモを行います。クラスタ監視フェーズでは、global、scrape_config、tls_config などの Prometheus の主要な設定項目について詳細に解説し、Namespace、DaemonSet、ConfigMap、ServiceAccount、ClusterRole、Deployment、Service といった必要な K8s リソースを段階的にデプロイする手順を説明します。また、Prometheus 自身、Node Exporter、Kubelet、Cadvisor、ApiServer といった異なる監視ターゲットに対する具体的な設定例を提供し、relabel_config の役割についても解説します。最後に、K8s クラスタを監視するために Prometheus を手動デプロイする際の主要な手順と注意点をまとめ、初心者にとって実用的な参考資料となることを目指しています。"
"tags":
  - "可観測性"
  - "Prometheus"
  - "Kubernetes"
  - "監視"
  - "技術"
  - "手動デプロイ"
  - "設定"
"date": "2020-11-05"
---

> 本記事の対象読者は、監視システムに触れ始めたばかりの方、および Prometheus についてほとんど知識を持たない方（本記事を執筆した時点の筆者自身のような）です。
>
>
>
> 本記事で Prometheus を構築するために使用した環境：
>
> - K8s バージョン: 1.19.3
>- Prometheus バージョン: 2.22.0
> - オペレーティングシステム: Archlinux at 2020.11
>- hosts を設定済み、Devbox のドメイン名は devbox
>
> ⚠️ ご注意ください：本記事で記載されているコマンドライン引数は、現在の環境に合わせて若干調整する必要があります（例：Prometheus バイナリパッケージのバージョンなど）。
>
>
>
> 以下に、推奨される事前読了項目をいくつか挙げます：
>
> 1. [可観測性：概念とベストプラクティス](https://github.com/lichuan0620/k8s-sre-learning-notes/blob/master/observability/OBSV-101.md) 可観測性に関する様々な基本概念を紹介しています。
>2. [Prometheus の初歩的な理解](https://github.com/lichuan0620/k8s-sre-learning-notes/blob/master/prometheus/PROM-101.md) Prometheus プロジェクトを紹介しています。
> 3. [Prometheus 公式サイトの紹介](https://prometheus.io/docs/introduction/overview/)

## 目標

K8s 上で手動で Prometheus を構築するにあたり、ここでは2つの規約を設けます。

1. 意図的に Helm-Chart、Prometheus Operator などの簡易デプロイ方法を使用しません。参考までに以下を挙げます：
   1. Prometheus コミュニティがメンテナンスする [Helm chart](https://github.com/prometheus-community/helm-charts)
   2. [Prometheus Operator](https://github.com/prometheus-operator/prometheus-operator)
   3. [Kube-Prometheus](https://github.com/prometheus-operator/kube-prometheus)
3. K8s 上で Prometheus を構築します。つまり、K8s が Prometheus サービスを管理し、上記で言及した Prometheus Operator とは異なり、ここでは関連する様々な YAML 設定ファイルを自分で記述します。
3. 以下の監視ターゲットを列挙します：
   1. Prometheus 自身
   2. Node exporter
   3. Kubelet
   4. Cadvisor
   5. ApiServer

それでは始めましょう！

<!--more-->

## ベアメタルでの Prometheus 概念検証

まず最初の直感は、ベアメタル上で概念検証を行い、まずは起動させてからさらに詳細な設定を実験し、最終的に Prometheus の各設定項目を理解した後、K8s 上に再デプロイするのは容易であるべきだということです。

> 私は手を抜こうと試みましたが、チュートリアルブログを検索したところ、どれも不明瞭で、ほとんどがすでに古くなっていることがわかり、結局半日を無駄にして公式サイトのドキュメントを読む羽目になりました。

### Prometheus のインストール

[ドキュメント](https://prometheus.io/docs/prometheus/2.22/getting_started/)の説明に従い、[ここ](https://prometheus.io/download/)から対応するプリコンパイル済みバイナリパッケージを直接ダウンロードします：

```bash
curl -LO "https://github.com/prometheus/prometheus/releases/download/v2.22.0/prometheus-2.22.0.linux-amd64.tar.gz"
tar -zxvf prometheus-2.22.0.linux-amd64.tar.gz
cd prometheus-2.22.0.linux-amd64
./prometheus --version
# 期待される出力は以下のようになります：
# prometheus, version 2.22.0 (branch: HEAD, revision: 0a7fdd3b76960808c3a91d92267c3d815c1bc354)
#  build user:    root@6321101b2c50
#  build date:    20201015-12:29:59
#  go version:    go1.15.3
#  platform:     linux/amd64
```

ディレクトリを確認すると、設定ファイル prometheus.yml が付属していることがわかります：

```yaml
# my global config
global:
 scrape_interval:   15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
 evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
 # scrape_timeout is set to the global default (10s).
# Alertmanager configuration
alerting:
 alertmanagers:
 - static_configs:
  - targets:
   # - alertmanager:9093
# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
 # - "first_rules.yml"
 # - "second_rules.yml"
# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
 # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
 - job_name: 'prometheus'
  # metrics_path defaults to '/metrics'
  # scheme defaults to 'http'.
  static_configs:
  - targets: ['localhost:9090']
```

ここで、先ほどダウンロードした Prometheus を実行して、自分自身を監視し、小さな達成感のフィードバックループを得ます：

```bash
./prometheus --config.file=prometheus.yml
```

この時点で Prometheus が起動したことがわかります。http://devbox:9090 にアクセスしてそのユーザーインターフェースを確認し、ランダムにクリックして Prometheus が提供する機能について大まかな感覚をつかみ、Prometheus が正常に動作しているときの挙動について認識を持ちましょう。

### Node Exporter の実行

次に、ベアメタル上で Node Exporter を実行し、本機の様々なメトリクスを観察します。

```bash
curl -LO "https://github.com/prometheus/node_exporter/releases/download/v1.0.1/node_exporter-1.0.1.linux-amd64.tar.gz"
tar -zxvf node_exporter-1.0.1.linux-amd64.tar.gz
cd node_exporter-1.0.1.linux-amd64
./node_exporter
```

次に、Prometheus がそこからメトリクスを収集するように設定を変更します。

```yaml
# my global config
global:
 scrape_interval:   15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
 evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
 # scrape_timeout is set to the global default (10s).
# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
 # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
 - job_name: 'prometheus'
  # metrics_path defaults to '/metrics'
  # scheme defaults to 'http'.
  static_configs:
  - targets: ['localhost:9090']
 - job_name: 'node-exporter'
  static_configs:
  - targets: ['localhost:9100']
```

Prometheus の Web UI を開き、`node-exporter` という名前の新しいターゲットが追加されたことを確認します。ワークロードを確認してみましょう（すべてのコアを占有する永遠にフィボナッチ数列を計算する[プログラム](https://github.com/Thrimbda/fiber)を1つ実行しています）：

![img](https://0xc1.space/images/2020/11/05/node-load.png)

これで、概念検証フェーズは無事完了しました。

> 注意：概念検証の段階として、ここではベアメタルデプロイの Prometheus を使用して直接 K8s クラスタを監視することは推奨しません。その理由は、クラスタ外から K8s コンポーネントにアクセスするには証明書の設定と適切なアクセス権限を持つ [ClusterRole](https://kubernetes.io/ja/docs/reference/access-authn-authz/rbac/) が必要だからです（ここでは、筆者がベアメタルデプロイの Prometheus を使用して K8s クラスタおよびその中の様々なコンポーネントを監視しようと試みた際に踏んだ様々な落とし穴については省略します）。

## Prometheus による K8s クラスタの監視

次に、Prometheus を通じて K8s クラスタを監視します。

### Prometheus の設定項目

Prometheus の紹介から、Prometheus は主に Pull ベースのデータ取得方式であることがわかります。したがって、サービスディスカバリが必要です。つまり、Prometheus にどこからデータを取得するかを知らせ、ユーザーが確認できるようにする必要があります。

では、まず最初に解決すべき問題は、**K8s クラスタのサービスディスカバリ**です。その秘密は必ず設定の中に隠されています。

[ドキュメント](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/)には、Prometheus の設定に関する詳細な説明があります。

以下のいくつかの設定項目について簡単に説明します（必ずしも互いに直交しているわけではありません）：

- [`<global>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#configuration-file)：この中の設定は他のすべての設定項目に影響し、他の設定項目のデフォルト値として機能します。
- [`<scrape_config>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#scrape_config)：監視タスクを定義し、Prometheus がどこからどのようにこのターゲットを監視すべきかを記述します。
- [`<tls_config>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#tls_config)：TLS 設定を記述します。
- [`<*_sd_config>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#kubernetes_sd_config)：Prometheus はこの一連の設定項目を通じて、一連の事前定義された監視ターゲットのサービスディスカバリ設定を提供します（sd は service discovery を表します）。
- [`<static_config>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#static_config)：Prometheus に事前定義されていない監視ターゲット（例えば、ベアメタルに手動でデプロイされた任意のサービス）に対しては、この設定項目を使用してサービスディスカバリを行うことができます。上記で概念検証を行った際に、この設定項目を使用しました。
- [`<relabel_config>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#relabel_config)：監視ターゲットの各メトリクスの取得を開始する前に、この設定項目を使用していくつかのラベルを変更することができます。Prometheus はいくつかの事前定義されたラベルルールを提供しており、relabel は複数段階で行うことができます。relabel が完了した後、`__` で始まるラベルは削除されます。

Prometheus の中核となる設定項目は `<scrape_config>` のようです。それぞれが監視タスクを定義し、namespace のような概念で、主に監視ターゲットの集約を提供します。その中で、`<*_sd_config>` または `<static_config>` を定義して、Prometheus に具体的にどのエンドポイントからデータを取得するか、およびこれらのエンドポイントをどのようにフィルタリングするかを指示します。

次に、実践を通じてこれらの設定項目への理解を深めましょう！

### Prometheus のデプロイ

デプロイの中心的な作業は、クラスタ内に Prometheus をデプロイするためにどのようなリソースが必要かを明確に考えることです。筆者はここで直接答えを公開します：

1. 専用の Namespace
2. node-exporter を管理するための DaemonSet
3. Node-exporter Service
4. ConfigMap による Prometheus の設定管理
5. Prometheus 専用の ServiceAccount
6. 十分な権限を持つ ClusterRole
7. ServiceAccount と ClusterRole を結びつける ClusterRoleBinding
8. Prometheus Deployment
9. Prometheus Service

RBAC が適用された K8s クラスタでは、Prometheus にクラスタの状態や様々なメトリクスを読み取るのに十分な権限を持つロールを定義する必要があります。したがって、5〜7番目の項目が必要です。

ここでは、筆者が自身の構築プロセスで蓄積した[リソース宣言のセット](https://github.com/Thrimbda/prometheus-set-up)を提供します。上記のリソースに加えて kube-state-metrics も含まれており、順番に操作するだけでデプロイされた Prometheus を手に入れることができます。

#### Node-exporter

Node-exporter については、マシン自体の監視であるため、各 Node に1つずつ必要です。同時に K8s のライフサイクル管理の恩恵を受けたいため、DaemonSet が最適な選択です。

コンテナ内で実行されるため、設定を行わないと実際の Node メトリクスを収集できません。したがって、Node-exporter がメトリクスを収集できるように、ホスト上の特別な場所をコンテナ内にマウントする必要があります。

```yaml
args:
- '--path.procfs=/host/proc'
- '--path.sysfs=/host/sys'
- '--path.rootfs=/host/root'
volumes:
- hostPath:
  path: /proc
 name: proc
- hostPath:
  path: /sys
 name: sys
- hostPath:
  path: /
 name: roo
```

そして、Service を通じて Prometheus が長期間アクセスできるエンドポイントを公開するだけです。

#### Prometheus

Prometheus は Deployment を使用してデプロイします。Prometheus をデプロイする前に、必要なエンドポイントにアクセスしてメトリクスを収集できるように十分な権限を設定する必要があります。RBAC が設定された K8s クラスタでは、ClusterRole/ServiceAccount/ClusterRoleBinding を通じてこの目標を達成します。設定が完了すると、Prometheus は ServiceAccount を通じて適切な認証を行い、必要なエンドポイントにアクセスします。

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
 name: prometheus
 labels:
  app.kubernetes.io/name: prometheus
rules:
 - apiGroups: [""]
  resources:
  - nodes
  - nodes/metrics
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
 - nonResourceURLs:
  - "/metrics"
  - "/metrics/cadviror"
  verbs: ["get"]
---
apiVersion: v1
kind: ServiceAccount
metadata:
 name: default
 namespace: monitoring-system
 labels:
  app.kubernetes.io/name: prometheus
---
apiVersion: rbac.authorization.k8s.io/v