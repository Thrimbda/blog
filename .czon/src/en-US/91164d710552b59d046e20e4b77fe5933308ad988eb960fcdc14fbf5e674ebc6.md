---
"title": "Manually Setting Up Prometheus on a Single-Node K8s Cluster"
"summary": "This article is a detailed guide on manually setting up the Prometheus monitoring system on a single-node Kubernetes cluster. It begins by introducing the setup environment, including K8s version 1.19.3 and Prometheus version 2.22.0, and clarifies that quick deployment methods like Helm-Chart or Prometheus Operator are not used. Instead, the setup is achieved by manually writing YAML configuration files. The content is divided into two parts: proof of concept and cluster monitoring. In the proof-of-concept phase, the author demonstrates how to run Prometheus and Node Exporter on bare metal and modify configuration files to monitor self and node metrics. In the cluster monitoring phase, it explains Prometheus's core configuration items, such as global, scrape_config, tls_config, etc., and gradually deploys the required K8s resources, including Namespace, DaemonSet, ConfigMap, ServiceAccount, ClusterRole, Deployment, and Service. The article also provides specific configuration examples for different monitoring targets (e.g., Prometheus itself, Node Exporter, Kubelet, Cadvisor, and ApiServer) and explains the role of relabel_config. Finally, the author summarizes the key steps and considerations for manually deploying Prometheus to monitor a K8s cluster, offering practical guidance for beginners."
"tags":
  - "Observability"
  - "Prometheus"
  - "Kubernetes"
  - "Monitoring"
  - "Technology"
  - "Manual Deployment"
  - "Configuration"
"date": "2020-11-05"
---

> The target audience for this article is those who are just starting to explore monitoring systems and have limited knowledge of Prometheus (much like the author when writing this article).
>
>
>
> Environment used for setting up Prometheus in this article:
>
> - K8s version: 1.19.3
> - Prometheus version: 2.22.0
> - Operating System: Archlinux as of 2020.11
> - Hosts configured, domain name for Devbox is devbox
>
> ⚠️ Note: The command-line parameters listed in this article need to be adjusted according to the current environment (e.g., Prometheus binary package version, etc.).
>
>
>
> Here are some recommended prerequisites:
>
> 1. [Observability: Concepts and Best Practices](https://github.com/lichuan0620/k8s-sre-learning-notes/blob/master/observability/OBSV-101.md) introduces various basic concepts of observability.
> 2. [Getting to Know Prometheus](https://github.com/lichuan0620/k8s-sre-learning-notes/blob/master/prometheus/PROM-101.md) introduces the Prometheus project.
> 3. [Introduction on the Prometheus Official Website](https://prometheus.io/docs/introduction/overview/)

## Goal

Since we are manually setting up Prometheus on K8s, we have two conventions here:

1. Deliberately avoid using quick deployment methods like Helm-Chart or Prometheus Operator. Here are some references:
   1. Prometheus community-maintained [Helm chart](https://github.com/prometheus-community/helm-charts)
   2. [Prometheus Operator](https://github.com/prometheus-operator/prometheus-operator)
   3. [Kube-Prometheus](https://github.com/prometheus-operator/kube-prometheus)
2. Set up Prometheus on K8s, meaning K8s manages the Prometheus service. Unlike the Prometheus Operator mentioned above, we will write all related YAML configuration files ourselves.
3. List the following monitoring targets:
   1. Prometheus
   2. Node Exporter
   3. Kubelet
   4. Cadvisor
   5. ApiServer

Let's get started!

<!--more-->

## Proof of Concept: Running Prometheus on Bare Metal

First, the intuition is to do a proof of concept on bare metal. Start by running it and experimenting with further configurations. Ultimately, once we understand Prometheus's various configuration items, redeploying it on K8s should be straightforward.

> I tried to take shortcuts by searching for tutorials and blogs, but they were unclear and mostly outdated. As a result, I wasted half a day and had to read the official documentation carefully.

### Installing Prometheus

According to the [documentation](https://prometheus.io/docs/prometheus/2.22/getting_started/), download the corresponding precompiled binary package directly from [here](https://prometheus.io/download/):

```bash
curl -LO "https://github.com/prometheus/prometheus/releases/download/v2.22.0/prometheus-2.22.0.linux-amd64.tar.gz"
tar -zxvf prometheus-2.22.0.linux-amd64.tar.gz
cd prometheus-2.22.0.linux-amd64
./prometheus --version
# expected output should be like this:
# prometheus, version 2.22.0 (branch: HEAD, revision: 0a7fdd3b76960808c3a91d92267c3d815c1bc354)
#  build user:    root@6321101b2c50
#  build date:    20201015-12:29:59
#  go version:    go1.15.3
#  platform:     linux/amd64
```

Check the directory and find a configuration file named `prometheus.yml`:

```yaml
# my global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'
    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.
    static_configs:
    - targets: ['localhost:9090']
```

Now, let's run the downloaded Prometheus to monitor itself and achieve a small feedback loop of satisfaction:

```bash
./prometheus --config.file=prometheus.yml
```

You can see that Prometheus has started. Access http://devbox:9090 to see its user interface. Click around randomly to get a general sense of Prometheus's features and understand how it behaves when running normally.

### Running Node Exporter

Now, let's run a Node Exporter on bare metal to observe various metrics of the local machine.

```bash
curl -LO "https://github.com/prometheus/node_exporter/releases/download/v1.0.1/node_exporter-1.0.1.linux-amd64.tar.gz"
tar -zxvf node_exporter-1.0.1.linux-amd64.tar.gz
cd node_exporter-1.0.1.linux-amd64
./node_exporter
```

Next, modify the configuration to let Prometheus collect metrics from it:

```yaml
# my global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'
    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.
    static_configs:
    - targets: ['localhost:9090']
  - job_name: 'node-exporter'
    static_configs:
    - targets: ['localhost:9100']
```

Open Prometheus's web UI and observe that a new target named `node-exporter` has been added. Check the workload (running a program that can occupy all cores by endlessly calculating Fibonacci numbers [here](https://github.com/Thrimbda/fiber)):

![img](https://0xc1.space/images/2020/11/05/node-load.png)

At this point, the proof-of-concept phase is successfully completed.

> Note: As part of the proof-of-concept, it is not recommended to directly use bare-metal-deployed Prometheus to monitor a K8s cluster. The reason is that accessing K8s components from outside the cluster requires configuring certificates and having appropriate access permissions via [ClusterRole](https://kubernetes.io/zh/docs/reference/access-authn-authz/rbac/) (this saves the author from recounting the various pitfalls encountered when trying to monitor a K8s cluster and its components with bare-metal Prometheus).

## Monitoring the K8s Cluster with Prometheus

Next, we will use Prometheus to monitor our K8s cluster.

### Prometheus Configuration Items

From the introduction to Prometheus, we know that Prometheus primarily uses a pull-based data acquisition method. Therefore, service discovery is needed to let Prometheus know where to pull data from, so users can view it.

The first problem to solve is: **Service discovery for the K8s cluster**—the secret must lie in the configuration.

The [documentation](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/) provides a detailed description of Prometheus configuration.

Here is a brief description of the following configuration items (they are not necessarily orthogonal to each other):

- [`<global>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#configuration-file): The configuration here applies to all other configuration items and serves as the default value for items in other configurations.
- [`<scrape_config>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#scrape_config): Defines a monitoring task, describing where and how Prometheus should monitor this target.
- [`<tls_config>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#tls_config): Describes TLS configuration.
- [`<*_sd_config>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#kubernetes_sd_config): Prometheus provides configuration for service discovery of a series of predefined monitoring targets through this series of configuration items (sd stands for service discovery).
- [`<static_config>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#static_config): For monitoring targets not predefined by Prometheus (e.g., any service manually deployed on bare metal), service discovery can be configured using this item. We used this configuration item during the proof-of-concept phase.
- [`<relabel_config>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#relabel_config): Before pulling metrics from monitoring targets, this configuration item can be used to modify some labels. Prometheus provides some predefined label rules. Relabeling can be done in multiple steps. After relabeling, labels prefixed with `__` are deleted.

It seems that the core configuration item in Prometheus is `<scrape_config>`. Each defines a monitoring task, similar to the concept of a namespace, mainly providing aggregation of monitoring targets. Within it, we define `<*_sd_config>` or `<static_config>` to tell Prometheus specifically which endpoints to pull data from and how to filter these endpoints.

Next, let's deepen our understanding of these configuration items through practice!

### Deploying Prometheus

The core work of deployment lies in clearly thinking about what resources are needed to deploy Prometheus in the cluster. The author directly reveals the answer here:

1. A dedicated Namespace
2. A DaemonSet to manage node-exporter
3. Node-exporter Service
4. Manage Prometheus configuration using ConfigMap
5. Prometheus-specific ServiceAccount
6. A ClusterRole with sufficient permissions
7. A ClusterRoleBinding that binds the ServiceAccount and ClusterRole together
8. Prometheus Deployment
9. Prometheus Service

On a K8s cluster with RBAC applied, we need to define a role with sufficient permissions for Prometheus to read cluster status and various metrics. Therefore, items 5-7 are required.

Here is a [collection of resource declarations](https://github.com/Thrimbda/prometheus-set-up) accumulated by the author during the setup process. In addition to the above resources, it also includes kube-state-metrics. Follow the steps in order to deploy Prometheus.

#### Node Exporter

For Node Exporter, since it monitors the machine itself, the requirement is one per Node. Since we also want to enjoy K8s lifecycle management, DaemonSet is the best choice.

Since it runs in a container, without configuration, it cannot collect real Node metrics. Therefore, special locations on the host need to be mounted in the container for Node Exporter to collect metrics.

```yaml
args:
  - '--path.procfs=/host/proc'
  - '--path.sysfs=/host/sys'
  - '--path.rootfs=/host/root'
volumes:
  - hostPath:
      path: /proc
    name: proc
  - hostPath:
      path: /sys
    name: sys
  - hostPath:
      path: /
    name: root
```

Then, expose the endpoint that Prometheus can access long-term via a Service.

#### Prometheus

Prometheus is deployed using a Deployment. Before deploying Prometheus, it needs to be configured with sufficient permissions to access necessary endpoints to collect metrics. In a K8s cluster with RBAC configured, this is achieved via ClusterRole/ServiceAccount/ClusterRoleBinding. After configuration, Prometheus uses the ServiceAccount for authentication to access the required endpoints.

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
  labels:
    app.kubernetes.io/name: prometheus
rules:
  - apiGroups: [""]
    resources:
      - nodes
      - nodes/metrics
      - services
      - endpoints
      - pods
    verbs: ["get", "list", "watch"]
  - nonResourceURLs:
      - "/metrics"
      - "/metrics/cadvisor"
    verbs: ["get"]
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: default
  namespace: monitoring-system
  labels:
    app.kubernetes.io/name: prometheus
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
  labels:
    app.kubernetes.io/name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
  - kind: ServiceAccount
    name: default
    namespace: monitoring-system
```

So far, we have all the prerequisites to achieve our monitoring goals. How do we drive Prometheus, this powerful engine, to fully utilize the environment we've set up for monitoring?

Combining the introduction to Prometheus configuration earlier, define four monitoring targets with four `<scrape_config>` items:

For node-exporter:

```yaml
- job_name: 'node-exporter'
  kubernetes_sd_configs:
    - role: endpoints
  relabel_configs:
    - source_labels: [__meta_kubernetes_service_name]
      regex: node-exporter
      action: keep
    - source_labels: [__meta_kubernetes_endpoint_node_name]
      target_label: node
    - source_labels: [__meta_kubernetes_pod_host_ip]
      target_label: host_ip
```

Since it's inside the cluster, no additional authentication is required, and HTTPS access is not needed.

Here, we further explain `<relabel_configs>` using the node-exporter example:

A label is an attribute of an endpoint. Different endpoints may have different values under the same label. What `<relabel_config>` does is modify and filter these labels to filter/modify the desired endpoints.

![img](https://0xc1.space/images/2020/11/05/node-exporter-target.png)

As you can see, in the config above, there are three relabel actions. The first means: from all values of the K8s service discovery **predefined** label `__meta_kubernetes_service_name`, filter according to the given regular expression "node-exporter". Based on the `action`, keep the matching target endpoints and discard the remaining values with the same label. The latter two relabel actions are to retain the semantic labels `node` and `host_ip` by renaming them. (Remember, labels starting with double underscores are eventually deleted.)

For Prometheus itself:

```yaml
- job_name: 'prometheus'
  kubernetes_sd_configs:
    - role: endpoints
  relabel_configs:
    - source_labels: [__meta_kubernetes_service_name]
      regex: prometheus
      action: keep
```

Use the same approach to filter endpoints.

For kubelet and cadvisor, the situation becomes slightly more complex:

```yaml
- job_name: 'kubelet'
  kubernetes_sd_configs:
    - role: node
  tls_config:
    # ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    # cert_file: /etc/secret/cert
    # key_file: /etc/secret/key
    insecure_skip_verify: true
  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
  scheme: https
- job_name: 'cadvisor'
  kubernetes_sd_configs:
    - role: node
  metrics_path: /metrics/cadvisor
  tls_config:
    # ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    # cert_file: /etc/secret/cert
    # key_file: /etc/secret/key
    insecure_skip_verify: true
  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
  scheme: https
```

Note that the role has changed to `node`, so Prometheus will collect metrics from `<node_ip>:10250/metrics` by default. Here, there is an additional `bearer_token_file` configuration item. Since kubelet does not allow