---
"title": "Spark 論文ノート"
"summary": "本稿はSparkに関する論文のノートです。SparkがRDD（Resilient Distributed Dataset）というデータ構造を通じて、MapReduceなどのシステムが持つ汎用性の限界を克服し、複数の並列操作にわたるデータの再利用をサポートする方法について紹介しています。記事では、RDDの作成方法、永続化戦略、プログラミングモデル（並列操作など）、およびScala上での実装詳細（遅延評価と一時性の特性を含む）を詳しく説明しています。実験結果では、特定のシナリオにおいてSparkがHadoopよりも10倍高速であることが示されています。最後に、Sparkの初期の利点、限界、および関連技術との比較をまとめています。"
"tags":
  - "Spark"
  - "RDD"
  - "分散システム"
  - "論文ノート"
  - "ビッグデータ"
  - "Scala"
  - "MapReduce"
"date": "2022-01-10"
---

MapReduceは非常に成功しましたが、このような非循環グラフを基盤とするシステムの多くは汎用的ではありませんでした。そのような中でSparkが登場し、**RDDという分散データ構造を通じて**、以下のような処理をサポートする分散計算フレームワークを提案しました。

> 複数の並列操作にわたって作業用データセットを再利用するもの

RDD (Resilient Distributed Dataset) は、失われた場合にDAG内の先行ノードから再構築可能な読み取り専用のデータ構造です。

SparkはScalaで実装されており、Scalaの特性は以下の通りです：
- JVM上で動作する言語
- 関数型プログラミングをサポート
- オブジェクト指向

## プログラミングモデル

### RDDの紹介

RDDは4つの方法で作成できます。

1.  HDFSなどのファイルシステムから作成
2.  Scalaのコレクションから作成
3.  既存のRDDから変換（flatMap、map、filterなどを使用）
4.  既存のRDDの永続化方法を変更（RDDは読み取り専用であり、変更操作があると論理的に新しいRDDが作成されます）

さらに、RDDは遅延評価（lazy）かつ一時的（ephemeral）なデータ構造です。ユーザーは以下の2つの方法でRDDを永続化できます：

-   **cache**を使用：キャッシュされたRDDも依然として遅延評価ですが、一時的ではなくなります。つまり、最初の評価後に保存され、再利用を待ちます。
-   **save**を使用：分散ファイルシステムに書き込みます。

ユーザーはアクセス速度とストレージ容量の間でトレードオフを考慮する必要があります。

### 並列操作

-   reduce - 結合則を満たす操作
-   collect
-   foreach - 副作用を持つ操作

## 例

-   ログ統計
-   ロジスティック回帰
-   ALS（交互最小二乗法）

遅延評価と一時性という2つの特性により、Sparkの動作はMapReduceと同様に見えます。しかし、キャッシュのステップを追加するだけで、計算を大幅に高速化できます。

## 実装

-   （論文執筆当時のバージョン）Mesos上に構築
-   実装の核心はRDDインターフェースにあり、Scalaのオブジェクト指向と関数型の特性を十分に活用しています。
    -   getPartitions
    -   getIterator(partition)
    -   getPreferredLocations(partition) - データ局所性の考慮のため
-   Scalaにおけるタスク（クロージャ）はJavaオブジェクトであるため、シリアライズして送信できます。実装過程ではScalaのバグも発見されました。
-   インタプリタ統合も実装されました。
-   論文執筆時点では、シャッフルはまだ実装されていませんでした。

## 実験結果

-   Hadoopを大きく上回り、10倍高速
-   使用したデータセットは小規模

## 関連研究

-   分散共有メモリ (Distributed Shared Memory)
-   MapReduce
-   Scala（DryadLINQに類似）

## 感想

-   まだ非常に初期の研究段階であり、著者は10倍の高速化というHadoopに対する効果に興奮して共有しています。
-   本記事の内容はやや概括的です。
-   関数型的で不変（immutable）であるため、遅延評価が可能です。
-   当時のHadoopも、当時のSparkも、MapReduce（の概念）には勝てませんでした。