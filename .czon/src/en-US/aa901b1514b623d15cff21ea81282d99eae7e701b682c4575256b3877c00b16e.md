---
"title": "2026 Work Log"
"summary": "This document is a work log from January 22nd to 24th, 2026. The author details daily practices in software development (e.g., legionmind-github-bridge, node-unit improvements) and system design (multi-agent systems) using AI Agents like opencode and legionmind. The log includes specific tasks completed, problems encountered (e.g., cluster security, Agent knowledge modeling), ideas generated (e.g., increasing Agent autonomy, designing an evaluation system), and plans for the following day. The core argument is that the author is focused on scaling personal capabilities through AI Agents and exploring efficient workflows and Agent evaluation methods. The conclusion is that a balance needs to be found between Agent autonomy, providing contextual knowledge, and managing personal energy."
"tags":
  - "Work Log"
  - "AI Agent"
  - "Software Development"
  - "Efficiency Management"
  - "Multi-Agent System"
  - "Automation"
  - "Personal Productivity"
"date": "2026-01-01"
---

# Table of Contents

1.  [2026](#orgf3197da)
    1.  [2026-01 January](#orge03e1ca)
        1.  [2026-01-22](#org4d65f86)
            1.  [What I did today:](#org1006a17)
            2.  [What I thought:](#orgdb0ae87)
            3.  [What do I plan to do tomorrow?](#org750daf2)
        2.  [2026-01-23](#org287b8dd)
            1.  [What I did today:](#orgf838e08)
            2.  [What I thought:](#org8998678)
            3.  [What do I plan to do tomorrow?](#orgc688fe4)
        3.  [2026-01-24](#org2a15db2)
            1.  [What I did today:](#orgab0f160)
            2.  [What I thought:](#org68bf2d9)
            3.  [What do I plan to do tomorrow?](#orge3ab04d)

<a id="orgf3197da"></a>

# 2026

<a id="orge03e1ca"></a>

## 2026-01 January

<a id="org4d65f86"></a>

### 2026-01-22

<a id="org1006a17"></a>

#### What I did today:

1.  Refactored the opencode-feishu-notifier; it now sends notifications to users in a predetermined manner.
2.  Continued having the AI work on legionmind-github-bridge. I started using opencode's multi-agent mode, which launched 5 agents to modify 5 issues. It ran for 2 hours straight, exhausting my 5-hour quota of codex tokens.
3.  A node in the sg cluster died today. I checked the logs and found it was under constant SSH brute-force attack attempts. This is not good. Briefly considered a few possible actions:
    - Disable password authentication.
    - Disable the SSH daemon's exposure to the entire internet.
    - Move the cluster behind a NAT.
4.  Handled some miscellaneous tasks. ZL is coming to Suzhou next week, spent some time making arrangements, but it didn't go smoothly. I don't plan to invest more mental energy into this.

<a id="orgdb0ae87"></a>

#### What I thought:

At this stage, I can only manage 2-3 things simultaneously. This includes development work, daily scheduling, thinking, and output. Exceeding this range leads to poor task management and easy fatigue. This is even with me offloading as much work as possible to AI Agents. Therefore, I think there are two areas for improvement:

- For coding tasks, I should maximize agent autonomy. Optimization goals include:
  1.  Disturb me as little as possible.
  2.  Let it do as much work as possible.
  3.  Improve the reliability of its work as much as possible.
- I also need to improve myself:
  1.  Manage my mental energy better to avoid quick burnout.
  2.  Improve my ability to work across multiple different contexts simultaneously, avoiding forgetfulness and disorganization, and implement progress management.

Based on the above thoughts, I think I can try two directions tomorrow:

1.  Design a multi-agent template for legionmind and experiment with it on a coding task in Yuan using opencode.
2.  Continue logging work to explore methods for managing mental energy and context.

<a id="org750daf2"></a>

#### What do I plan to do tomorrow?

1.  As mentioned above, conduct a multi-agent experiment.
2.  Continue working on legionmind-github-bridge.
3.  If time permits, work on cluster security.

&#x2014;

Overall, my main focus right now is using AI to scale myself up, and then try to scale others.

<a id="org287b8dd"></a>

### 2026-01-23

Had a bit of a cold today, with a headache. Low productivity, but I'm glad I started doing daily summaries.

<a id="orgf838e08"></a>

#### What I did today:

1.  With AI assistance, designed a multi-agent system. This system hasn't been systematically polished yet.
2.  Made further progress on legionmind-github-bridge.
3.  Modified the preemption design and implementation of node-unit. Previously, when a node-unit failed, all deployments under it were cleared. Now, they are cleaned up one by one.
4.  Took the CFFEX (China Financial Futures Exchange) exam required for opening a futures trading account. It required the camera to be on the entire time, no minimizing the window or switching screens. Fortunately, unlimited attempts were allowed, which couldn't stop me. Passed with a high score of 95.

<a id="org8998678"></a>

#### What I thought:

My goal is to achieve agent autonomy with minimal friction. My current workflow is:

1.  legionmind serves as an SOP for development work; it's an agent skill. I like the concept of agent skills.
2.  opencode serves as the agent entity. I use its capabilities like bash / tool calling / langraph / command / subagent. If I ever need to move away from opencode, these would be on my implementation list.
3.  My current headache is how to combine skills and these sub-agents.

Had a headache all day, only clearing up a bit in the evening. I realized writing these thoughts at the end of the day might not be the best approach. Maybe I should only record facts and summarize thoughts the next morning after waking up.

<a id="orgc688fe4"></a>

#### What do I plan to do tomorrow?

1.  Use this multi-agent system to do something, maybe connect Gate's investment account.
2.  Continue with legionmind-github-bridge.
3.  Cluster security, if time permits.
4.  Restart work time tracking. (Important)
5.  SY's friends are visiting tomorrow, so work time might be preempted.

<a id="org2a15db2"></a>

### 2026-01-24

Slept in until 11 AM today, feeling completely refreshed. Haven't slept so freely in a long time.

<a id="orgab0f160"></a>

#### What I did today:

1.  Deployed the new version of node-unit. I was relatively confident in deploying it because I have fairly comprehensive end-to-end tests. Specifically, a docker container starts a timescaledb (postgresql17), then two node-units are started, and 21 `@yuants/portal` deployments are inserted into the database for testing, eventually converging to a state where each node-unit handles half.

    This test basically covers the scenario where a bunch of unclaimed deployments appear, and then two node-units come online, allowing observation of them taking turns preempting deployments. What it's really missing is a workload that actually consumes CPU/memory, and the scenario where a node-unit goes offline for some reason.

2.  Used the new multi-agent version of legionmind in Yuan to tackle the problem of outputting account flows for the vendor-gate earn account. I had the agent first use legion for documentation creation, producing the following documents in total:

        .legion/tasks/vendor-gate
        ├── context.md
        ├── docs
        │   ├── api-doc.md
        │   ├── pr-body.md
        │   ├── report-walkthrough.md
        │   ├── rfc.md
        │   ├── spec-bench.md
        │   ├── spec-dev.md
        │   ├── spec-obs.md
        │   └── spec-test.md
        ├── plan.md
        └── tasks.md

    Feels like a decent workflow now. However, there's some conflict between my new multi-agent system and legionmind's original documentation writing. I should carefully consider the boundaries of each task. For example, specifications on how each type of document should be written should be placed in separate skills, and legionmind should be a description of the workflow. Each type of agent should be able to load a few smaller skills to assist in their work.

    Another shortcoming was that it made a mistake on its first run, outputting the account flow to `account-actions-with-credential.ts`. This was because I asked it to reference vendor-okx to complete the earn account integration. I gave this instruction because currently only okx's earn account is also integrated as an account. However, the AI learned some outdated practices from it. The current exchange integration standard is to publish all accounts via `provideExchangeServices`, not using `provideAccountActionsWithCredential` to integrate accounts.

    This knowledge is something a brand new AI Agent doesn't possess. How should such knowledge be modeled? How should I provide such project context as an external brain for the AI Agent? This is a question worth pondering deeply. Need to think about it carefully tomorrow.

3.  Cooked in the afternoon to entertain SY's friends. It wore me out. So, back to work tomorrow~

<a id="org68bf2d9"></a>

#### What I thought:

- As mentioned above, I need to carefully consider how to compactly design an external brain for AI Agents. The simplest could start with a set of AGENT.md files. I've tried this before, but the overhead of maintaining these documents themselves is quite high. Distinguishing between noise and truly valuable experience is a difficult problem. Currently, it seems memory, like other prompts, might just involve an additional loop for the agent to update its own memory. The most important thing is still how to measure the results of AI Agent work.

- Regarding the above point, I saw an article that I found very interesting. Let me summarize it in my own words: First, the evaluation of a single agent step can be categorized into several types:
  1.  Static tool eval: Compiler, linter, unit tests, e2e tests.
  2.  Model eval: Using another LLM to judge based on a prompt we define.
  3.  Human eval: I judge.

  Then, systematic evaluation of an Agent system comes in two forms:
  1.  Capability-based: Answers what this agent can do? The pass rate might be low, e.g., I want to use legion to gradually execute larger, more difficult tasks, feeling like exploring a new frontier.
  2.  Regression-based: Can it still perform previously mastered capabilities? For example, repeatedly testing some tasks to ensure stable implementation.

  So, when a new capability is introduced, it should transition from capability-based to regression-based evaluation.

  The article also mentions two important metrics: `pass@K` and `pass^K`.
  - pass@k: At least one success in k attempts. The more attempts, the higher the probability of at least one success. Applicable: Scenarios where you only care about "finding at least one usable solution."
  - pass^k: All k attempts must succeed. The more attempts, the harder it is to maintain consistency. Applicable: Scenarios where users expect reliable production from the agent every time.

  FYI: [Reference this article](https://medium.com/ai-software-engineer/anthropic-new-guide-shows-how-to-build-quality-ai-agents-without-getting-fooled-29f378ec2609)

- Energy levels are still a bit low. Worked a bit in the afternoon, cooked dinner, and felt tired. When will I be like CZ and not need to sleep?

<a id="orge3ab04d"></a>

#### What do I plan to do tomorrow?

1.  Think about this eval agent model and continue iterating on this multi-agent system.
2.  Cluster security issue, must tackle it.
3.  legion-github-bridge