---
"title": "Quellcode-Lektüre: Harbor-Operator"
"summary": "Dieser Artikel ist eine technische Analyse des Quellcodes von Harbor-Operator. Der Autor beginnt mit den Designprinzipien (wie 'Worse is Better') und stellt die Eigenschaften von Harbor-Operator vor, das in Golang auf der Kubernetes-Plattform implementiert ist. Der Artikel analysiert schwerpunktmäßig die Kernarchitektur, einschließlich der Lösung von Abhängigkeiten zwischen Ressourcen durch einen Dependency Graph und der Realisierung der Reconcile-Logik für elf verschiedene CRDs durch einen einheitlichen Controller, was die Code-Wiederverwendbarkeit erheblich steigert. Der Artikel erläutert auch detailliert das Design von Schlüsselkomponenten wie ResourceManager und ProcessFunc und zeigt die hervorragenden Praktiken von Harbor-Operator im Streben nach Einfachheit, Konsistenz und Wartbarkeit."
"tags":
  - "Operator"
  - "Kubernetes"
  - "Golang"
  - "Quellcode-Analyse"
  - "Harbor"
  - "Design-Patterns"
  - "Abhängigkeitsgraph"
  - "Controller"
"date": "2022-01-30"
---

<!--more-->

<a id="orgdafefdb"></a>

## Vorbereitungen

<a id="org081213e"></a>

### Warum Harbor-Operator?

<a id="org55a74c9"></a>

#### Worse is Better?

Was ist gute Software?

In einem berühmten Artikel aus den späten 80er Jahren, *The Rise of Worse is Better*, erwähnt der Autor, dass ein gutes Softwaredesign die vier Eigenschaften *Einfachheit*, *Korrektheit*, *Konsistenz* und *Vollständigkeit* berücksichtigen sollte.

Der Autor erwähnt zwei Softwaredesign-Philosophien, die vorläufig *the right thing* und *worse is better* genannt werden (es ist notwendig anzumerken, dass diese Benennung nicht abwertend gemeint ist); beide Designphilosophien drehen sich um die oben genannten vier Eigenschaften, unterscheiden sich jedoch in der Priorisierung dieser Eigenschaften.

---

<a id="orgbebeeee"></a>

##### The right thing

-   **Einfachheit** - Das Design muss einfach und verständlich sein. Eine einfache Schnittstelle ist wichtiger als eine einfache Implementierung.
-   **Korrektheit** - Das Design muss korrekt sein. Hierbei darf es keine Kompromisse geben.
-   **Konsistenz** - Konsistenz ist genauso wichtig wie Korrektheit. Daher können Einfachheit und Vollständigkeit etwas zurückstehen.
-   **Vollständigkeit** - Das Design muss eine Vielzahl möglicher Szenarien berücksichtigen. Die Vollständigkeit darf nicht übermäßig zugunsten der Einfachheit geopfert werden.

<a id="org948c614"></a>

##### Worse is better

-   **Einfachheit** - Das Design muss einfach und verständlich sein. Eine einfache Implementierung ist wichtiger als eine einfache Schnittstelle. Einfachheit ist die wichtigste Eigenschaft.
-   **Korrektheit** - Das Design muss korrekt sein, allerdings ist Einfachheit ein wenig wichtiger als Korrektheit.
-   **Konsistenz** - Das Design darf nicht zu inkonsistent sein. Konsistenz kann zugunsten der Einfachheit geopfert werden. Um die Vollständigkeit zu gewährleisten, kann Konsistenz geopfert werden, solange die Einfachheit erhalten bleibt.
-   **Vollständigkeit** - Das Design muss eine Vielzahl möglicher Szenarien berücksichtigen. Die Vollständigkeit kann jederzeit geopfert werden, um die Einfachheit des Designs zu gewährleisten.

---

Anschließend führt der Autor viele Beispiele für beide an, um zu argumentieren, warum *worse-is-better* damals die Softwarebranche eroberte.

Diese beiden Philosophien sind nicht besser oder schlechter. Auch heute finden wir sie in unserer Umgebung, und die Realität bewegt sich oft zwischen beiden. Wir hoffen, ein exzellentes, ästhetisch wertvolles Design zu erstellen, müssen aber auch Kosten und menschliche Faktoren berücksichtigen. Letztendlich muss qualitativ angemessene, funktionierende Software geliefert werden, um reale Probleme zu lösen, und die Kosten für die Entwicklung und Wartung der Software dürfen den Wert des Problems selbst auf keinen Fall übersteigen.

<a id="org514ce0b"></a>

#### Golang - die Sprache

Golang ist fast ein Paradebeispiel für die *worse is better*-Philosophie:

-   Es vereint die jahrelange praktische Erfahrung von Google mit C++.
-   Es ist so einfach, ohne komplexe Funktionen, dass es für die Lösung eines Problems im Grunde nur einen *Building Block* gibt. Das bedeutet:
    -   Es ist fast ohne Aufwand für die Sprache selbst leicht zu beherrschen.
    -   Der Code ist sehr gut lesbar.
-   Schnelle Kompilierung, sogar auf Kosten von Generics.
-   Parallele Aufgaben können sehr einfach über Goroutinen ausgeführt werden.
-   Die Ausnahmebehandlung (*exception stack*) als Sprachmerkmal wurde fast aufgegeben, was eine Fehlerprüfung und -behandlung erzwingt.
-   Einmal kompiliert, überall ausführbar.

<a id="org2432232"></a>

#### Kubernetes - die Plattform

Kubernetes ist allen bekannt, daher werde ich nicht den Besserwisser spielen und es in einem Satz zusammenfassen: Es bietet ein konzeptionell sehr einfaches API-Design, ergänzt durch einen Reconcile-Mechanismus aus der Kybernetik, der es containerisierter Software ermöglicht, automatisiert bereitgestellt, skaliert und betrieben zu werden.

K8s erlaubt Entwicklern durch die Öffnung dieser API-Spezifikation und des Reconcile-Mechanismus, dessen Fähigkeiten zu erweitern. Entwickler können das *Operator Pattern* implementieren: Das Wissen über die Konfiguration, Bereitstellung (Day-1) und den Betrieb, die Sicherung, die Fehlerbehebung (Day-2) der Software wird in Software geschrieben, die die Software bedient, um diese komplexen, fehleranfälligen Operationen zu automatisieren, die Zuverlässigkeit zu erhöhen und die Kosten zu senken.

---

Der Grund für die Wahl von Harbor Operator ist also sein hervorragendes Design. Auf einer exzellenten Plattform und mit einfachen Sprachmerkmalen, ohne übermäßige Tricks, realisiert es durch einige Schlüsseldesigns, die den SOLID-Designprinzipien entsprechen, ein pragmatisches und ästhetisch wertvolles Softwaresystem, das als Praktiker der *the right thing*-Philosophie angesehen werden kann.

Der Code des Autors hat fast keine Kommentare, ist aber außergewöhnlich gut lesbar, was auch dem gesamten System zu verdanken ist.

<a id="org6815286"></a>

## Ziel

Die Abstraktion und Vereinfachung von Problemen geht zwangsläufig mit dem Verlust von Flexibilität einher, während Harbor Operator die Flexibilität vollständig aufgibt, um maximale kognitive Entlastung zu bringen, sodass die Entwicklung des Operators eher der Deklaration einer Softwarekonfiguration gleicht.

Das manuelle Schreiben eines Operators mit client-go ist dank des Fehlens von Generics in Golang eine Qual. Das gesamte Projekt wäre mit einer riesigen Menge an *Boilerplate Code* (Template-Code) gefüllt. Ich glaube, selbst wenn jemand wirklich von Hand mit client-go schreiben würde, würde niemand wirklich bei Null anfangen.

So entstand kubebuilder. Es abstrahiert die Erstellung des Kubernetes Clients, das Abhören von Anfragen des Kubernetes API Servers und das Einreihen von Anfragen in Warteschlangen in öffentliche Bibliotheken (*controller runtime*) und öffentliche Tools (*controller tools*) und kann für Entwickler Gerüstcode generieren, der sich auf die Entwicklung der Geschäftslogik zur Verarbeitung von Änderungsanfragen an API-Objekte konzentriert.

Kubebuilder bewahrt immer noch einen Hauch von Vielfalt in der Geschäftslogik, während Harbor Operator darauf aufbauend weiter nach Perfektion strebt, Flexibilität vollständig opfert, um konzeptionelle Konsistenz und Einfachheit zu verfolgen, und die Geschäftsanforderungen, denen es gegenübersteht, sich tatsächlich sehr gut für diesen Ansatz eignen.

Daher ist unser Hauptziel in dieser Quellcode-Lektüre, von Harbor Operator zu lernen:

-   Wie Day-1-Operationen durchgeführt werden.
-   Wie der Redundanzgrad des Operator-Codes weiter reduziert wird, indem derselbe Controller-Code verwendet wird, um den Controller für elf verschiedene CRD-Ebenen zu implementieren.
-   Wie DAG genutzt wird, um Abhängigkeitsprobleme zwischen Ressourcen zu lösen – der Autor scheint dafür sogar ein Patent angemeldet zu haben.

Darüber hinaus werden wir uns nicht schwerpunktmäßig mit folgenden Aspekten befassen:

-   Day-2-Operationen in Harbor Operator – tatsächlich ist dieser Teil der Funktionalität in der aktuellen Version noch nicht stabil.
-   Dem Quellcode und den Funktionen von Harbor selbst.

<a id="org345a335"></a>

## Quellcode-Lektüre

<a id="org1198d5f"></a>

### Statische Struktur

<a id="orgb32de77"></a>

#### Verzeichnisstruktur

Hier sind nur die Verzeichnisse aufgelistet.

```
    root
    ├── apis
    │   ├── goharbor.io
    │   │   └── v1alpha3
    │   └── meta
    │       └── v1alpha1
    ├── controllers
    │   ├── controller_string.go
    │   ├── controllers.go
    │   └── goharbor
    │       ├── chartmuseum
    │       ├── controller_test.go
    │       ├── core
    │       ├── exporter
    │       ├── harbor
    │       ├── harborcluster
    │       ├── internal
    │       ├── jobservice
    │       ├── notaryserver
    │       ├── notarysigner
    │       ├── portal
    │       ├── registry
    │       ├── registryctl
    │       └── trivy
    ├── pkg
    │   ├── builder
    │   ├── cluster
    │   │   ├── controllers
    │   │   │   ├── cache
    │   │   │   ├── common
    │   │   │   ├── database
    │   │   │   │   └── api
    │   │   │   ├── harbor
    │   │   │   └── storage
    │   │   ├── gos
    │   │   ├── k8s
    │   │   └── lcm
    │   ├── config
    │   │   ├── harbor
    │   │   └── template
    │   ├── controller
    │   │   ├── errors
    │   │   ├── internal
    │   │   │   └── graph
    │   │   └── mutation
    │   ├── event-filter
    │   ├── exit
    │   ├── factories
    │   │   ├── application
    │   │   ├── logger
    │   │   └── owner
    │   ├── graph
    │   ├── harbor
    │   ├── image
    │   ├── manager
    │   ├── resources
    │   │   ├── checksum
    │   │   └── statuscheck
    │   ├── scheme
    │   ├── setup
    │   ├── status
    │   ├── template
    │   ├── tracing
    │   ├── utils
    │   │   └── strings
    │   └── version
    ...
```

<a id="orgfc0f08e"></a>

#### Wichtige Schnittstellen

![img](https://0xc1.space/images/2022/01/30/harbor-operator-class.svg)

<a id="org290c6c2"></a>

#### Systemarchitektur

Bis Version v1.0.1 ist Harbor Operator hauptsächlich für die Day-1-Operationen des Harbor-Systems verantwortlich.
![img](https://0xc1.space/images/2022/01/30/harbor-operator-arch.png)

<a id="org41c8944"></a>

### Das Wesentliche im Blick: HarborCluster

Lassen Sie uns zunächst einige weniger kritische Teile ausblenden: Die CRD `HarborCluster` und die Implementierung ihres Controllers.

Warum ist sie besonders? Schauen wir uns zunächst ihre Position in der Systemarchitektur an: Sie befindet sich auf der obersten Ebene und verwaltet das Harbor-System selbst sowie alle davon abhängigen Stateful Services. Dies muss aus der Projektgeschichte und ihrer besonderen Stellung in der Systemarchitektur erklärt werden.

Aus Sicht der Systemarchitektur weist die CRD `HarborCluster` in ihrer Definition große Ähnlichkeit mit der CRD `Harbor` auf, und der Code enthält viele Redundanzen, was nicht sehr schön aussieht. Dies liegt daran, dass sie als die oberste (äußerste) CRD im gesamten System direkt dem Benutzer gegenübersteht; sie muss in der Lage sein, dem Benutzer alle notwendigen Konfigurationselemente für die Bereitstellung von Harbor bereitzustellen. Da Harbor selbst ein stateless Service ist, erfordert eine vollständige Bereitstellung außerdem, dass die CRD `HarborCluster` alle von Harbor abhängigen Stateful Services verwaltet, einschließlich Postgres, Minio und Redis.

Die notwendigen Informationen für das Harbor-System selbst sind bereits in der CRD `Harbor` definiert, daher besteht der redundante Teil in der CRD `HarborCluster` darin, diese Informationen vollständig und korrekt an die CRD `Harbor` weiterzugeben. Darüber hinaus muss die CRD `HarborCluster` auch die CRDs der Stateful Services verwalten, die außerhalb ihrer eigenen Zuständigkeitsgrenzen liegen, und kann daher die Controller-Logik in Harbor und allen Unterkomponenten von Harbor nicht vollständig nutzen.

Aus historischer Sicht war Harbor Operator ursprünglich ein privates Projekt von OVH Cloud und wurde später an die goharbor-Community gespendet. Betrachtet man also den Git-History, liegt der Grund für die große Inkonsistenz zwischen der CRD-Definition von `HarborCluster` und ihrer Controller-Implementierung im Vergleich zu anderen Controllern im System darin, dass sie ein späterer Community-Beitrag ist und die von ihr übernommenen Funktionen beim ursprünglichen Design von Harbor Operator nicht berücksichtigt wurden.

Die Implementierung des HarborCluster-Controllers selbst unterscheidet sich nicht wesentlich von den meisten Controllern, die mit Controller-Runtime implementiert sind, und wird daher nicht detailliert untersucht.

---

HarborCluster Controller

![img](https://0xc1.space/images/2022/01/30/harbor-cluster-controller.png)

---

Harbor Core Controller

![img](https://0xc1.space/images/2022/01/30/harbor-core-controller.png)

---

<a id="orgd9c3526"></a>

### Lösung von Abhängigkeiten zwischen Ressourcen: Dependency Graph

Der Abhängigkeitsgraph ist ein relativ unabhängiges Modul im gesamten Projekt, aber es übernimmt tatsächlich die Rolle der Ausführungs-Engine für alle Controller in Harbor Operator. Im Wesentlichen wird beobachtet, dass zwischen verschiedenen Ressourcentypen in Kubernetes gegenseitige Abhängigkeiten bestehen. Die Bereitstellung und Reconcile einiger Ressourcen hängt von der Bereitstellung und Reconcile anderer Ressourcen ab, z. B. kann ein Deployment von einem ConfigMap abhängen. Letztendlich bilden diese Abhängigkeiten einen Abhängigkeitsgraphen, der eigentlich ein DAG sein sollte. Hier benötigen wir die folgende Schnittstellendefinition:

```go
    package graph

    type Resource interface{}

    type RunFunc func(context.Context, Resource) error

    type Manager interface {
            Run(ctx context.Context) error
            AddResource(ctx context.Context, resource Resource, blockers []Resource, run RunFunc) error
    }

    type resourceManager struct {
       resources map[Resource][]Resource
       functions map[Resource]RunFunc

       lock sync.Mutex
    }
```

-   `Resource` definiert eine abstrakte Ressource. Da sich dieses Modul nicht dafür interessiert, was eine Ressource genau darstellt, und um bei den Einschränkungen der Ausdruckskraft der Sprache maximale Flexibilität zu bewahren, wird der Top-Typ `interface{}` verwendet.
-   `RunFunc` ist dafür verantwortlich, die spezifische Operation für eine Ressource durchzuführen. Hier steht `RunFunc` vor einem Typsicherheitsproblem: `interface{}` bedeutet, dass der Compiler nichts über diesen Typ weiß und daher nichts damit anfangen kann. Aber `RunFunc` muss mit diesem Typ, der alles sein kann, etwas anstellen. Daher gehen wir davon aus, dass es eine Typumwandlung (*type assertion*) durchführen muss. Wenn die `RunFunc` jeder Ressource den konkreten Typ manuell umwandeln müsste, wäre das sehr langweilig und widerlich. Später werden wir uns ansehen, wie Harbor Operator die Drecksarbeit an einer Stelle konzentriert.
-   `Manager` hat nur zwei Methoden: Ressource hinzufügen und diesen Graphen ausführen. Beide müssen untersucht werden.
-   Die Datenstruktur `resourceManager`, die `Manager` implementiert, ist ebenfalls einfach definiert:
    -   Eine Map `resource -> blockers`
    -   Eine Map `resource -> runFunc`
    -   Ein `lock` zur Behandlung der Nebenläufigkeit von Map-Operationen. Hier können wir sehen, dass der Autor Datenstrukturen wie `Sync.Map`, die nebenläufigkeitssicher sind, aber die Typsicherheit verlieren, nicht mag. Das macht noch neugieriger, wie der Autor die vielen (11 Komponenten) `RunFunc` handhabt.

Da es sich um einen Graphen handelt, muss es eine Datenstruktur für den Graphen und eine Factory-Methode zum Erstellen dieses Graphen geben. Die Datenstruktur von `resourceManager` wirkt etwas steif, es ist unklar, ob es sich um den eigentlichen Graphen handelt.

<a id="org75cbb07"></a>

#### AddResource

Gemäß der Signatur kann beobachtet werden, dass `AddResource` die hinzuzufügende Ressource selbst, alle ihre Abhängigkeiten und die entsprechende `runFunc` hinzufügt. Es ist bemerkenswert, dass zuerst Ressourcen hinzugefügt werden müssen, die von keiner anderen Ressource abhängen (d. h. mit Ausgangsgrad 0).

```go
    func (rm *resourceManager) AddResource(ctx context.Context, resource Resource, blockers []Resource, run RunFunc) error {
       if resource == nil {
          return nil
       }

       if run == nil {
          return errors.Errorf("unsupported RunFunc value %v", run)
       }

       span, _ := opentracing.StartSpanFromContext(ctx, "addResource", opentracing.Tags{
          "Resource": resource,
       })
       defer span.Finish()

       nonNilBlockers := []Resource{}

       for _, blocker := range blockers {
          if blocker == nil {
             continue
          }

          nonNilBlockers = append(nonNilBlockers, blocker)

          _, ok := rm.resources[blocker]
          if !ok {
             return errors.Errorf("unknown blocker %+v", blocker)
          }
       }

       rm.lock.Lock()
       defer rm.lock.Unlock()

       _, ok := rm.resources[resource]
       if ok {
          return errors.Errorf("resource %+v already added", resource)
       }

       rm.resources[resource] = nonNilBlockers
       rm.functions[resource] = run

       return nil
    }
```

<a id="org4cb9f3a"></a>

#### Run

Fast die gesamte wichtige Logik in diesem Paket befindet sich in der Methode `Run`. Sehen wir uns zuerst die erste Hälfte an:

```go
    func (rm *resourceManager) Run(ctx context.Context) error {
       span, ctx := opentracing.StartSpanFromContext(ctx, "walkGraph", opentracing.Tags{
          "Nodes.count": len(rm.resources),
       })
       defer span.Finish()

       g := errgroup.Group{}
       l := logger.Get(ctx)

       for _, no := range rm.getGraph(ctx) {
       ...
```

Da ist es! `getGraph`. Es sieht so aus, als ob der Graph erstellt werden soll. Geht man hinein, stellt man fest, dass `resourceManager` tatsächlich nur ein Builder ist. Der eigentliche Graph ist darin versteckt, ausgedrückt als Adjazenzliste. Auf den ersten Blick sieht es sogar komplex aus:

```go
    type node struct {
       resource Resource
       fn       RunFunc

       parent      chan error
       parentLock  *sync.Mutex
       parentCount int

       children     []chan<- error
       childrenLock []*sync.Mutex
    }

    func (no *node) Wait(ctx context.Context) error {...}
    func (no *node) Terminates(err error) (result error) {...}
    func (no *node) AddChild(child *node) {...}
```

Warum sind `parent` und `children` ein Channel? Warum werden so viele Locks benötigt? Schauen wir uns den Erstellungsprozess des Graphen an:

```go
    func (rm *resourceManager) getGraph(ctx context.Context) []*node {
       span, _ := opentracing.StartSpanFromContext(ctx, "getGraph")
       defer span.Finish()

       rm.lock.Lock()
       defer rm.lock.Unlock()

       graph := make(map[Resource]*node, len(rm.resources))
       result := make([]*node, len(rm.resources))

       i := 0

       for resource, blockers := range rm.resources {
          blockerCount := len(blockers)

          node := &node{
             resource: resource,
             fn:       rm.functions[resource],

             parent:      make(chan error, blockerCount),
             parentLock:  &sync.Mutex{},
             parentCount: blockerCount,

             children:     []chan<- error{},
             childrenLock: []*sync.Mutex{},
          }
          graph[resource] = node
          result[i] = node

          i++

          blockers := blockers

          defer func() {
             for _, blocker := range blockers {
                graph[blocker].AddChild(node)
             }
          }()
       }

       return result
    }
```

Die Abhängigkeitsbeziehung wurde also umgekehrt. Jetzt zeigt die abhängige Ressource auf die Ressource, von der sie abhängt. Für jede Ressource wird ein `node` konstruiert, und für jede Abhängigkeit dieser Ressource wird der `parent`-Channel dieser Ressource zu den `children` der abhängigen Ressource hinzugefügt. Der endgültige Graph ist eine Sammlung von `node`s.

Das ist sicherlich verwirrend. Schauen wir uns also den Ausführungsprozess an:

```go
    for _, no := range rm.getGraph(ctx) {
       no := no

       g.Go(func() (err error) {

          defer func() {
             err := no.Terminates(err)
             if err != nil {
                l.Error(err, "failed to terminate node when running graph")
             }
          }()

          err = no.Wait(ctx)
          if err != nil {
             return err
          }

          err = no.fn(ctx, no.resource)

          return err
       })
    }
```

Sehr simpel und direkt. Für jeden `node` wird gewartet, bis seine eingehenden `node`s ausgeführt sind, dann wird seine eigene `runFunc` ausgeführt, und potenzielle Fehler werden an alle wartenden `node`s weiter hinten in der Kette weitergegeben, um vorzeitig abgebrochen zu werden.

Hier verstehe ich überhaupt nicht, warum nicht eine topologische Sortierung verwendet wird, um dieses klar definierte klassische Problem zu lösen.

<a id="orgdcd001c"></a>

#### Initialisierung

```go
    Die Initialisierung des GraphManager verwendet eine thread-lokale globale Variable, die nach der Initialisierung in die Luft (ctx) geworfen wird. Dies ist eine gängige Methode der Abhängigkeitsinjektion in verschiedenen API-Frameworks.
    func (c *Controller) NewContext(req ctrl.Request) context.Context {
            ctx := context.TODO()
            application.SetName(&ctx, c.GetName())
            application.SetVersion(&ctx, c.GetVersion())
            application.SetGitCommit(&ctx, c.GetGitCommit())
            ctx = sgraph.WithGraph(ctx)

            logger.Set(&ctx, c.Log.WithValues("request", req))

            return ctx
    }

    func WithGraph(ctx context.Context) context.Context {
            return context.WithValue(ctx, &graphKey, graph.NewResourceManager())
    }

    func Get(ctx context.Context) graph.Manager {
            g := ctx.Value(&graphKey)
            if g == nil {
                    return nil
            }

            return g.(graph.Manager)
    }
```

<a id="org73ef8b0"></a>

### Code-Wiederverwendbarkeit maximieren: Controller

Abgesehen vom zuvor ausgeklammerten HarborCluster-Controller kombinieren alle Controller der Komponenten in Harbor Operator direkt denselben Controller, extrahieren die gemeinsame Logik aller Controller und verwenden dasselbe `Run`, dasselbe `Reconcile`. Wie wird das gemacht?

-   Welche Logik wurde extrahiert?
-   Wie werden Unterschiede behandelt?
-   Was wurde geopfert?

<a id="orgbd581d5"></a>

#### Datenstruktur

Die Implementierung der Schnittstelle durch den Controller ist, abgesehen von der Implementierung von `Reconciler`, nicht besonders interessant. Schauen wir uns also zunächst die Datenstrukturdefinition des Controllers an:

```go
    type ResourceManager interface {
            AddResources(context.Context, resources.Resource) error
            NewEmpty(context.Context) resources.Resource
    }

    type Controller struct {
            client.Client

            BaseController controllers.Controller
            Version        string
            GitCommit      string

            ConfigStore *configstore.Store
            rm          ResourceManager
            Log         logr.Logger
            Scheme      *runtime.Scheme
    }
```

Die Dinge, die wir nicht gut kennen, sind nur `BaseController` und `rm`.

`BaseController` ist im Grunde ein Identifikator, der Informationen über den Controller selbst und einige Label-Informationen identifiziert. Die logischen Unterschiede zwischen verschiedenen Controllern können also nur in `ResourceManager` liegen. `ResourceManager` scheint ebenfalls eine sehr einfache Schnittstelle zu sein, und die Implementierungen von `ResourceManager` sind tatsächlich die jeweiligen konkreten Controller. Wir werden die konkreten Beispiele für `ResourceManager` am Ende untersuchen.

```go
    type Controller int

    const (
       Core                Controller = iota // core
       JobService                            // jobservice
       Portal                                // portal
       Registry                              // registry
       RegistryController                    // registryctl
       ChartMuseum                           // chartmuseum
       Exporter                              // exporter
       NotaryServer                          // notaryserver
       NotarySigner                          // notarysigner
       Trivy                                 // trivy
       Harbor                                // harbor
       HarborCluster                         // harborcluster
       HarborConfiguration                   // harborconfiguration
    )

    func (c Controller) GetFQDN() string {
       return fmt.Sprintf("%s.goharbor.io", strings.ToLower(c.String()))
    }

    func (c Controller) Label(suffix ...string) string {
       return c.LabelWithPrefix("", suffix...)
    }

    func (c Controller) LabelWithPrefix(prefix string, suffix ...string) string {
       var suffixString string
       if len(suffix) > 0 {
          suffixString = "/" + strings.Join(suffix, "-")
       }

       if prefix != "" {
          prefix = "." + prefix
       }

       return fmt.Sprintf("%s%s%s", prefix, c.GetFQDN(), suffixString)
    }
```

<a id="orgc9dc9b0"></a>

#### Reconcile-Logik

Wie schafft es der Controller also, mit nur einem `Reconcile` die gesamte Familie von elf Harbor-CRDs zusammen mit so vielen Systemressourcen zu reconciliieren?

Basierend auf den bereits bekannten Informationen sollte für jede CRD ein `ResourceManager` verwendet werden, um die verschiedenen Ressourcen zu definieren, die diese CRD erstellen und reconciliieren muss. Diese Ressourcen definieren ihre Abhängigkeiten über den Abhängigkeitsgraphen, und für jede CRD wird eine konkrete `RunFunc` geschrieben, um die endgültige Reconcile durchzuführen.

```go
    func (c *Controller) Reconcile(req ctrl.Request) (ctrl.Result, error) {
       ctx := c.NewContext(req)

       span, ctx := opentracing.StartSpanFromContext(ctx, "reconcile", opentracing.Tags{
          "resource.namespace": req.Namespace,
          "resource.name":      req.Name,
          "controller":         c.GetName(),
       })
       defer span.Finish()

       l := logger.Get(ctx)

       // Fetch the instance

       object := c.rm.NewEmpty(ctx)

       ok, err := c.GetAndFilter(ctx, req.NamespacedName, object)
       if err != nil {
          // Error reading the object
          return ctrl.Result{}, err
       }

       if !ok {
          // Request object not found, could have been deleted after reconcile request.
          // Owned objects are automatically garbage collected. For additional cleanup logic use finalizers.
          l.Info("Object does not exists")

          return ctrl.Result{}, nil
       }

       if !object.GetDeletionTimestamp().IsZero() {
          logger.Get(ctx).Info("Object is being deleted")

          return ctrl.Result{}, nil
       }

       owner.Set(&ctx, object)

       if err := c.Run(ctx, object); err != nil {
          return c.HandleError(ctx, object, err)
       }

       return ctrl.Result{}, c.SetSuccessStatus(ctx, object)
    }
```

Sehr klassische Reconcile-Logik. Es scheint, dass der ganze Trick in `c.Run` steckt:

```go
    func (c *Controller) Run(ctx context.Context, owner resources.Resource) error {
       span, ctx := opentracing.StartSpanFromContext(ctx, "run")
       defer span.Finish()

       logger.Get(ctx).V(1).Info("Reconciling object")

       if err := c.rm.AddResources(ctx, owner); err != nil {
          return errors.Wrap(err, "cannot add resources")
       }

       if err := c.PrepareStatus(ctx, owner); err != nil {
          return errors.Wrap(err, "cannot prepare owner status")
       }

       return sgraph.Get(ctx).Run(ctx)
    }
```

Tatsächlich taucht `rm` hier auf. Nachdem die für einen bestimmten Controller benötigten Ressourcen hinzugefügt wurden, scheint `PrepareStatus` ein einheitlicher zu sein. Kombiniert man den Quellcode dieser Methode mit der CRD-Definition, stellt man fest, dass davon ausgegangen wird, dass alle Komponenten denselben Status haben. Wieder ein Design, das Flexibilität zugunsten von Einfachheit und Konsistenz opfert. Tatsächlich folgt dieses Design den von K8s empfohlenen Standards und kann beim Entwerfen von CRDs als Referenz dienen. Hier wird nicht weiter darauf eingegangen.

Letzte Zeile: `sgraph.Get(ctx).Run(ctx)`. Der Abhängigkeitsgraph kommt, aus der Luft (ctx) geholt. Damit schließt sich der Kreis für diesen Teil der Logik. Die verbleibende Frage ist: Wie konstruieren die konkreten Controller, die `ResourceManager` implementieren, den Abhängigkeitsgraphen und ihre eigene `RunFunc`?

<a id="orgb7ed9a6"></a>

### Code als Konfiguration: ResourceManager

Der letzte Schritt ist eigentlich folgerichtig.

Alle Controller, die `ResourceManager` implementieren, sollten gleichberechtigt sein. Wir werden das anhand des Beispiels `harbor core` untersuchen.

Abgesehen von den Teilen, die zur Erzeugung konkreter K8s-Ressourcen dienen, sollte der Teil, der die `ResourceManager`-Schnittstelle implementiert, betrachtet werden.

```go
    func (r *Reconciler) NewEmpty(_ context.Context) resources.Resource {
       return &goharborv1.Core{}
    }

    func (r *Reconciler) AddResources(ctx context.Context, resource resources.Resource) error {
       core, ok := resource.(*goharborv1.Core)
       if !ok {
          return serrors.UnrecoverrableError(errors.Errorf("%+v", resource), serrors.OperatorReason, "unable to add resource")
       }

       service, err := r.GetService(ctx, core)
       if err != nil {
          return errors.Wrap(err, "cannot get service")
       }

       _, err = r.Controller.AddServiceToManage(ctx, service)
       if err != nil {
          return errors.Wrapf(err, "cannot add service %s", service.GetName())
       }

       configMap, err := r.GetConfigMap(ctx, core)
       if err != nil {
          return errors.Wrap(err, "cannot get configMap")
       }

       configMapResource, err := r.Controller.AddConfigMapToManage(ctx, configMap)
       if err != nil {
          return errors.Wrapf(err, "cannot add configMap %s", configMap.GetName())
       }

       secret, err := r.GetSecret(ctx, core)
       if err != nil {
          return errors.Wrap(err, "cannot get secret")
       }

       secretResource, err := r.Controller.AddSecretToManage(ctx, secret)
       if err != nil {
          return errors.Wrapf(err, "cannot add secret %s", secret.GetName())
       }

       deployment, err := r.GetDeployment(ctx, core)
       if err != nil {
          return errors.Wrap(err, "cannot get deployment")
       }

       _, err = r.Controller.AddDeploymentToManage(ctx, deployment, configMapResource, secretResource)
       if err != nil {
          return errors.Wrapf(err, "cannot add deployment %s", deployment.GetName())
       }

       err = r.AddNetworkPolicies(ctx, core)

       return errors.Wrap(err, "network policies")
    }
```

Meine Güte, abgesehen davon, dass Ressourcen in einer bestimmten Reihenfolge hinzugefügt werden müssen, ist das im Grunde ein deklaratives Design. Wenn man einen neuen Controller hinzufügen möchte, ist es kinderleicht: Man muss nur wissen, welche Ressourcen dieser Controller reconciliieren soll, und muss sich nicht um die konkrete Reconcile-Logik kümmern.

Moment, müssen wir die `RunFunc` nicht selbst implementieren? Das ist die letzte Frage unserer Quellcode-Lektüre. Sehen wir uns an, wie Harbor Operator den Reconcile-Prozess einer beliebigen Ressource verallgemeinert und zu einer einzigen Funktion abstrahiert.

Nehmen wir zum Beispiel `r.Controller.AddServiceToManage(ctx, service)`.

```go
    func (c *Controller) AddServiceToManage(ctx context.Context, resource *corev1.Service, dependencies ...graph.Resource) (graph.Resource, error) {
       if resource == nil {
          return nil, nil
       }

       mutate, err := c.GlobalMutateFn(ctx)
       if err != nil {
          return nil, err
       }

       res := &Resource{
          mutable:   mutate,
          checkable: statuscheck.True,
          resource:  resource,
       }

       g := sgraph.Get(ctx)
       if g == nil {
          return nil, errors.Errorf("no graph in current context")
       }

       return res, g.AddResource(ctx, res, dependencies, c.ProcessFunc(ctx, resource, dependencies...))
    }
```

Es gibt zwei interessante Punkte:

1.  Die Definition von `Resource`, die wir vorher nicht gesehen haben.
2.  Der Aufruf von `Graph.AddResource` erscheint. Die Konstruktion der `RunFunc`, die uns interessiert, geschieht hier. Später werden wir das untersuchen.

Schauen wir uns zunächst dieses `Resource` an. Denken Sie daran, dass in `Graph` der konkrete Typ von `Resource` nicht von Interesse ist, daher wurde dort ein `interface{}` angegeben. Hier ist `Resource` von größerem Interesse, daher ist es wichtiger:

```go
    package controller

    type Resource struct {
            mutable   resources.Mutable
            checkable resources.Checkable
            resource  resources.Resource
    }

    package resources

    type Mutable func(context.Context, runtime.Object) error

    func (m *Mutable) AppendMutation(mutate Mutable) {
       old := *m
       *m = func(ctx context.Context, resource runtime.Object) error {
          if err := old(ctx, resource); err != nil {
             return err
          }

          return mutate(ctx, resource)
       }
    }

    func (m *Mutable) PrependMutation(mutate Mutable) {
       old := *m
       *m = func(ctx context.Context, resource runtime.Object) error {
          if err := mutate(ctx, resource); err != nil {
             return err
          }

          return old(ctx, resource)
       }
    }

    type Resource interface {
       runtime.Object
       metav1.Object
    }

    type Checkable func(context.Context, runtime.Object) (bool, error)
```

Man kann sehen, dass es sich im Wesentlichen um eine generische K8s-Ressource handelt, die von Harbor Operator zusätzlich gekapselt wurde.

Diese zusätzliche Kapselung besteht aus `checkable` und `mutable`.

`Checkable` definiert die Prüfung der Gültigkeit einer Ressource und ist relativ einfach.

`Mutable` sieht auf den ersten Blick kompliziert aus, ist aber im Grunde eine einfache Monaden-Komposition.

---

`Mutable` bildet eine Monade. Im Gegensatz zur Funktionskomposition erzeugt jede Komposition ein zusätzliches Ergebnis, das die Nebeneffekte der Berechnung ausdrückt, sodass die Funktion nicht direkt nacheinander angewendet werden kann. In einigen funktionalen Sprachen wird der *Fish Operator* `>=>` bereitgestellt, um die Monaden-Komposition zu realisieren.

Die Signatur des Fish Operators in Scala-Syntax lautet wie folgt:

```go
    def >=>[A, B, C](f: A => M[B], g: B => M[C]): A => M[C]
```

In einfachen Worten: Die `mutable`-Datenstruktur ermöglicht es, viele Mutationsfunktionen in einer bestimmten Reihenfolge zu kombinieren. Bei einem Fehler wird direkt abgebrochen.

---

Damit sind die Voraussetzungen für die Untersuchung der Konstruktion von `RunFunc` vollständig. Lassen Sie uns abschließend sehen, wie Harbor Operator diese Voraussetzungen nutzt, um für völlig unterschiedliche Ressourcen mithilfe derselben Logik die konkrete Implementierung von Reconcile zu konstruieren.

<a id="orgcce49ab"></a>

### Das letzte Rätsel: ProcessFunc

`ProcessFunc` ist im Wesentlichen eine Funktion höherer Ordnung, die mithilfe eines Closures einen `depManager` einfängt, der hauptsächlich zur Berechnung und Änderung der Checksum der Ressource selbst und ihrer Abhängigkeiten dient.

Die konstruierte `RunFunc` prüft zunächst, ob sich die Ressource und ihre Abhängigkeiten geändert haben. Wenn nicht, wird einfach die Bereitschaft (*ready*) überprüft und das war's. Andernfalls wird die Checksum für die nächste Prüfung aktualisiert und dann `c.applyAndCheck` aufgerufen, um die Änderung tatsächlich zu reconciliieren.

```go
    func (c *Controller) ProcessFunc(ctx context.Context, resource runtime.Object, dependencies ...graph.Resource) func(context.Context, graph.Resource) error { // nolint:funlen
            depManager := checksum.New(c.Scheme)

            depManager.Add(ctx, owner.Get(ctx), true)

            gvks, _, err := c.Scheme.ObjectKinds(resource)
            if err == nil {
                    resource.GetObjectKind().SetGroupVersionKind(gvks[0])
            }

            for _, dep := range dependencies {
                    if dep, ok := dep.(*Resource); ok {
                            gvks, _, err := c.Scheme.ObjectKinds(dep.resource)
                            if err == nil {
                                    dep.resource.GetObjectKind().SetGroupVersionKind(gvks[0])
                            }

                            depManager.Add(ctx, dep.resource, false)
                    }
            }

            return func(ctx context.Context, r graph.Resource) error {
                    res, ok := r.(*Resource)
                    if !ok {
                            return nil
                    }

                    span, ctx := opentracing.StartSpanFromContext(ctx, "process")
                    defer span.Finish()

                    namespace, name := res.resource.GetNamespace(), res.resource.GetName()

                    gvk := c.AddGVKToSpan(ctx, span, res.resource)
                    l := logger.Get(ctx).WithValues(
                            "resource.apiVersion", gvk.GroupVersion(),
                            "resource.kind", gvk.Kind,
                            "resource.name", name,
                            "resource.namespace", namespace,
                    )

                    logger.Set(&ctx, l)
                    span.
                            SetTag("resource.name", name).
                            SetTag("resource.namespace", namespace)

                    changed, err := c.Changed(ctx, depManager, res.resource)
                    if err != nil {
                            return errors.Wrap(err, "changes detection")
                    }

                    if !changed {
                            l.V(0).Info("dependencies unchanged")

                            err = c.EnsureReady(ctx, res)

                            return errors.Wrap(err, "check")
                    }

                    res.mutable.AppendMutation(func(ctx context.Context, resource runtime.Object) error {
                            if res, ok := resource.(metav1.Object); ok {
                                    depManager.AddAnnotations(res)
                            }

                            return nil
                    })

                    err = c.applyAndCheck(ctx, r)

                    return errors.Wrapf(err, "apply %s (%s/%s)", gvk, namespace, name)
            }
    }
```

Die eigentliche Reconcile-Logik steckt in `applyAndCheck`, die die zuvor in `Resource` registrierte `mutable`-Funktion verwendet.

```go
    func (c *Controller) applyAndCheck(ctx context.Context, node graph.Resource) error {
       span, ctx := opentracing.StartSpanFromContext(ctx, "applyAndCheck")
       defer span.Finish()

       res, ok := node.(*Resource)
       if !ok {
          return serrors.UnrecoverrableError(errors.Errorf("%+v", node), serrors.OperatorReason, "unable to apply resource")
       }

       err := c.Apply(ctx, res)
       if err != nil {
          return errors.Wrap(err, "apply")
       }

       err = c.EnsureReady(ctx, res)

       return errors.Wrap(err, "check")
    }

    func (c *Controller) Apply(ctx context.Context, res *Resource) error {
       span, ctx := opentracing.StartSpanFromContext(ctx, "apply")
       defer span.Finish()

       l := logger.Get(ctx)

       l.V(1).Info("Deploying resource")

       resource := res.resource

       if err := res.mutable(ctx, resource); err != nil {
          return errors.Wrap(err, "mutate")
       }

       err := c.Client.Patch(ctx, resource, client.Apply, &client.PatchOptions{
          Force:        &force,
          FieldManager: application.GetName(ctx),
       })
       if err != nil {
          l.Error(err, "Cannot deploy resource")

          if apierrs.IsForbidden(err) {
             return serrors.RetryLaterError(err, "dependencyStatus", err.Error())
          }

          if apierrs.IsInvalid(err) {
             return serrors.UnrecoverrableError(err, "dependencySpec", err.Error())
          }

          return err
       }

       return nil
    }
```

Nachdem alle Operationen abgeschlossen sind, wird `c.EnsureReady` aufgerufen, um die zuvor registrierte `checkable`-Funktion aufzurufen und den Reconcile-Prozess abzuschließen.

Damit ist die Untersuchung der wichtigen Designs im Code von Harbor Operator, die uns interessieren, abgeschlossen. Es ist wirklich beeindruckend.