---
"title": "Manuelle Einrichtung von Prometheus auf einem K8s Single-Node-Cluster"
"summary": "Dieser Artikel ist eine detaillierte Anleitung zur manuellen Einrichtung des Prometheus-Monitoring-Systems auf einem Kubernetes Single-Node-Cluster. Zunächst wird die Umgebung vorgestellt, einschließlich K8s Version 1.19.3 und Prometheus Version 2.22.0. Es wird klargestellt, dass keine schnellen Bereitstellungsmethoden wie Helm-Chart oder Prometheus Operator verwendet werden, sondern stattdessen YAML-Konfigurationsdateien manuell erstellt werden. Der Inhalt gliedert sich in zwei Teile: Proof of Concept und Cluster-Monitoring. Im Proof-of-Concept-Teil demonstriert der Autor, wie Prometheus und Node Exporter auf Bare Metal ausgeführt und die Konfigurationsdateien angepasst werden, um eigene und Node-Metriken zu überwachen. Im Cluster-Monitoring-Teil werden die Kernkonfigurationsoptionen von Prometheus wie global, scrape_config, tls_config usw. detailliert erläutert und die erforderlichen K8s-Ressourcen schrittweise bereitgestellt, darunter Namespace, DaemonSet, ConfigMap, ServiceAccount, ClusterRole, Deployment und Service. Der Artikel bietet auch konkrete Konfigurationsbeispiele für verschiedene Monitoring-Ziele (wie Prometheus selbst, Node Exporter, Kubelet, Cadvisor und ApiServer) und erklärt die Funktion von relabel_config. Abschließend fasst der Autor die wichtigsten Schritte und Überlegungen zur manuellen Bereitstellung von Prometheus zur Überwachung eines K8s-Clusters zusammen und bietet praktische Referenzen für Einsteiger."
"tags":
  - "Observability"
  - "Prometheus"
  - "Kubernetes"
  - "Monitoring"
  - "Technologie"
  - "Manuelle Bereitstellung"
  - "Konfiguration"
"date": "2020-11-05"
---

> Die Zielgruppe dieses Artikels sind Personen, die gerade erst mit Monitoring-Systemen in Berührung gekommen sind, sowie die benachteiligte Gruppe, die wenig über Prometheus weiß (so wie der Autor zum Zeitpunkt der Verfassung dieses Artikels).
>
>
>
> Die in diesem Artikel verwendete Umgebung für die Einrichtung von Prometheus:
>
> - K8s Version: 1.19.3
>- Prometheus Version: 2.22.0
> - Betriebssystem: Archlinux Stand 2020.11
>- Hosts konfiguriert, Domainname von Devbox ist devbox
>
> ⚠️ Bitte beachten Sie: Die in diesem Artikel aufgeführten Befehlszeilenparameter müssen je nach aktueller Umgebung leicht angepasst werden (z.B. Version des Prometheus-Binärpakets usw.).
>
>
>
> Hier sind einige empfohlene Vorab-Lektüren aufgeführt:
>
> 1. [Observability: Konzepte und Best Practices](https://github.com/lichuan0620/k8s-sre-learning-notes/blob/master/observability/OBSV-101.md) stellt verschiedene grundlegende Konzepte der Observability vor.
>2. [Erste Schritte mit Prometheus](https://github.com/lichuan0620/k8s-sre-learning-notes/blob/master/prometheus/PROM-101.md) stellt das Prometheus-Projekt vor.
> 3. [Die offizielle Einführung auf der Prometheus-Website](https://prometheus.io/docs/introduction/overview/)

## Ziel

Da es um die manuelle Einrichtung von Prometheus auf K8s geht, legen wir hier zwei Konventionen fest:

1. Wir verzichten bewusst auf schnelle Bereitstellungsmethoden wie Helm-Chart oder Prometheus Operator. Hier einige Referenzen:
   1. Der von der Prometheus-Community gepflegte [Helm chart](https://github.com/prometheus-community/helm-charts)
   2. [Prometheus Operator](https://github.com/prometheus-operator/prometheus-operator)
   3. [Kube-Prometheus](https://github.com/prometheus-operator/kube-prometheus)
2. Die Einrichtung von Prometheus auf K8s bedeutet, dass K8s für die Verwaltung des Prometheus-Dienstes verantwortlich ist. Im Gegensatz zum oben genannten Prometheus Operator werden wir hier die relevanten YAML-Konfigurationsdateien selbst schreiben.
3. Folgende Monitoring-Ziele werden aufgelistet:
   1. Prometheus
   2. Node Exporter
   3. Kubelet
   4. Cadvisor
   5. ApiServer

Legen wir los!

<!--more-->

## Proof of Concept: Prometheus auf Bare Metal ausführen

Der erste Gedanke ist ein Proof of Concept auf Bare Metal. Zuerst lassen wir es laufen und experimentieren dann mit weiteren Konfigurationen. Sobald wir die verschiedenen Konfigurationsoptionen von Prometheus verstanden haben, sollte die erneute Bereitstellung auf K8s ein Kinderspiel sein.

> Ich wollte versuchen, faul zu sein. Nach der Suche nach Tutorial-Blogs stellte ich fest, dass diese unklar und größtenteils veraltet waren. Letztendlich habe ich einen halben Tag verschwendet und musste mich doch mit der Dokumentation auf der offiziellen Website auseinandersetzen.

### Prometheus installieren

Gemäß der [Dokumentation](https://prometheus.io/docs/prometheus/2.22/getting_started/) laden Sie einfach das entsprechende vorkompilierte Binärpaket [hier](https://prometheus.io/download/) herunter:

```bash
curl -LO "https://github.com/prometheus/prometheus/releases/download/v2.22.0/prometheus-2.22.0.linux-amd64.tar.gz"
tar -zxvf prometheus-2.22.0.linux-amd64.tar.gz
cd prometheus-2.22.0.linux-amd64
./prometheus --version
# Erwartete Ausgabe sollte etwa so aussehen:
# prometheus, version 2.22.0 (branch: HEAD, revision: 0a7fdd3b76960808c3a91d92267c3d815c1bc354)
#  build user:    root@6321101b2c50
#  build date:    20201015-12:29:59
#  go version:    go1.15.3
#  platform:     linux/amd64
```

Ein Blick ins Verzeichnis zeigt eine mitgelieferte Konfigurationsdatei prometheus.yml:

```yaml
# my global config
global:
 scrape_interval:   15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
 evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
 # scrape_timeout is set to the global default (10s).
# Alertmanager configuration
alerting:
 alertmanagers:
 - static_configs:
  - targets:
   # - alertmanager:9093
# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
 # - "first_rules.yml"
 # - "second_rules.yml"
# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
 # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
 - job_name: 'prometheus'
  # metrics_path defaults to '/metrics'
  # scheme defaults to 'http'.
  static_configs:
  - targets: ['localhost:9090']
```

Jetzt starten wir den gerade heruntergeladenen Prometheus, um sich selbst zu überwachen, und erhalten eine kleine positive Rückmeldung:

```bash
./prometheus --config.file=prometheus.yml
```

Sie können sehen, dass Prometheus jetzt gestartet ist. Rufen Sie http://devbox:9090 auf, um seine Benutzeroberfläche zu sehen. Klicken Sie sich durch, um einen allgemeinen Eindruck von den Funktionen von Prometheus zu bekommen und zu verstehen, wie sich Prometheus im normalen Betrieb verhält.

### Node Exporter ausführen

Jetzt führen wir einen Node Exporter auf Bare Metal aus, um verschiedene Metriken des lokalen Systems zu beobachten.

```bash
curl -LO "https://github.com/prometheus/node_exporter/releases/download/v1.0.1/node_exporter-1.0.1.linux-amd64.tar.gz"
tar -zxvf node_exporter-1.0.1.linux-amd64.tar.gz
cd node_exporter-1.0.1.linux-amd64
./node_exporter
```

Als nächstes passen wir die Konfiguration an, damit Prometheus Metriken daraus sammelt.

```yaml
# my global config
global:
 scrape_interval:   15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
 evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
 # scrape_timeout is set to the global default (10s).
# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
 # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
 - job_name: 'prometheus'
  # metrics_path defaults to '/metrics'
  # scheme defaults to 'http'.
  static_configs:
  - targets: ['localhost:9090']
 - job_name: 'node-exporter'
  static_configs:
  - targets: ['localhost:9100']
```

Öffnen Sie die Web-UI von Prometheus und beobachten Sie, dass ein neues Target namens `node-exporter` hinzugefügt wurde. Überprüfen Sie die Arbeitslast (es läuft ein [Programm](https://github.com/Thrimbda/fiber), das die Fibonacci-Folge für immer berechnet und alle Kerne auslastet):

![img](https://0xc1.space/images/2020/11/05/node-load.png)

Damit ist die Proof-of-Concept-Phase erfolgreich abgeschlossen.

> Hinweis: Als Proof of Concept wird nicht empfohlen, den auf Bare Metal bereitgestellten Prometheus direkt zur Überwachung des K8s-Clusters zu verwenden. Der Grund dafür ist, dass der Zugriff auf K8s-Komponenten von außerhalb des Clusters die Konfiguration von Zertifikaten und einen entsprechenden [ClusterRole](https://kubernetes.io/zh/docs/reference/access-authn-authz/rbac/) mit Zugriffsberechtigungen erfordert (hier werden die verschiedenen Fallstricke weggelassen, die der Autor erlebt hat, als er versuchte, den auf Bare Metal bereitgestellten Prometheus zur Überwachung des K8s-Clusters und seiner Komponenten zu verwenden).

## Überwachung des K8s-Clusters mit Prometheus

Als nächstes wollen wir unseren K8s-Cluster mit Prometheus überwachen.

### Konfigurationsoptionen von Prometheus

Aus der Einführung in Prometheus geht hervor, dass Prometheus hauptsächlich auf Pull-basierter Datenerfassung basiert. Daher ist eine Service Discovery erforderlich, d.h. Prometheus muss wissen, woher es Daten abrufen kann, damit Benutzer sie einsehen können.

Die erste zu lösende Frage ist also: **Service Discovery für den K8s-Cluster** – das Geheimnis muss in der Konfiguration verborgen sein.

Die [Dokumentation](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/) enthält eine detaillierte Beschreibung der Prometheus-Konfiguration.

Einige dieser Konfigurationsoptionen werden kurz beschrieben (sie sind nicht unbedingt orthogonal zueinander):

- [`<global>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#configuration-file): Die darin enthaltenen Konfigurationen wirken sich auf alle anderen Konfigurationsoptionen aus und dienen als Standardwerte für Elemente in anderen Konfigurationen.
- [`<scrape_config>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#scrape_config): Definiert einen Monitoring-Job und beschreibt, woher und wie Prometheus dieses Ziel überwachen soll.
- [`<tls_config>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#tls_config): Beschreibt die TLS-Konfiguration.
- [`<*_sd_config>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#kubernetes_sd_config): Prometheus bietet mit dieser Reihe von Konfigurationsoptionen Konfigurationen für die Service Discovery einer Reihe vordefinierter Monitoring-Ziele (sd steht für Service Discovery).
- [`<static_config>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#static_config): Für Monitoring-Ziele, die nicht von Prometheus vordefiniert sind (z.B. beliebige manuell auf Bare Metal bereitgestellte Dienste), kann diese Konfigurationsoption für die Service Discovery verwendet werden. Im Proof of Concept oben haben wir diese Konfigurationsoption verwendet.
- [`<relabel_config>`](https://prometheus.io/docs/prometheus/2.22/configuration/configuration/#relabel_config): Bevor mit dem Abrufen der Metriken der Monitoring-Ziele begonnen wird, können mit dieser Konfigurationsoption einige Labels geändert werden. Prometheus bietet einige vordefinierte Label-Regeln. Relabeling kann in mehreren Schritten erfolgen. Nach Abschluss des Relabelings werden Labels mit dem Präfix __ gelöscht.

Es scheint, dass die Kernkonfigurationsoption in Prometheus `<scrape_config>` ist. Jedes definiert einen Monitoring-Job, ähnlich einem Namespace, und bietet hauptsächlich eine Aggregation von Monitoring-Zielen. Darin teilen wir Prometheus durch die Definition von `<*_sd_config>` oder `<static_config>` mit, von welchen Endpunkten genau Daten abgerufen werden sollen und wie diese Endpunkte gefiltert werden sollen.

Lassen Sie uns diese Konfigurationsoptionen durch praktische Übungen vertiefen!

### Bereitstellung von Prometheus

Die Kernarbeit bei der Bereitstellung besteht darin, genau zu überlegen, welche Ressourcen für die Bereitstellung von Prometheus im Cluster benötigt werden. Der Autor gibt die Antwort direkt hier bekannt:

1. Einen dedizierten Namespace
2. Ein DaemonSet zur Verwaltung von node-exporter
3. Node-exporter Service
4. Verwaltung der Prometheus-Konfiguration mit ConfigMap
5. Ein dedizierter ServiceAccount für Prometheus
6. Eine ClusterRole mit ausreichenden Berechtigungen
7. Ein ClusterRoleBinding, das den ServiceAccount und die ClusterRole miteinander verbindet
8. Prometheus Deployment
9. Prometheus Service

In einem K8s-Cluster mit aktiviertem RBAC müssen wir für Prometheus eine Rolle mit ausreichenden Berechtigungen definieren, um den Clusterstatus und verschiedene Metriken lesen zu können. Daher sind die Punkte 5-7 erforderlich.

Hier ist eine [Sammlung von Ressourcendeklarationen](https://github.com/Thrimbda/prometheus-set-up), die der Autor während seines eigenen Einrichtungsprozesses gesammelt hat. Neben den oben genannten Ressourcen enthält sie auch kube-state-metrics. Wenn Sie in der angegebenen Reihenfolge vorgehen, erhalten Sie einen bereitgestellten Prometheus.

#### Node Exporter

Für den Node Exporter, der den Rechner selbst überwacht, ist die Anforderung einer pro Node. Da wir gleichzeitig die Lebenszyklusverwaltung von K8s nutzen möchten, ist DaemonSet die beste Wahl.

Da er in einem Container läuft, kann er ohne Konfiguration keine echten Node-Metriken sammeln. Daher müssen spezielle Orte auf dem Host im Container gemountet werden, damit der Node Exporter Metriken sammeln kann.

```yaml
args:
- '--path.procfs=/host/proc'
- '--path.sysfs=/host/sys'
- '--path.rootfs=/host/root'
volumes:
- hostPath:
  path: /proc
 name: proc
- hostPath:
  path: /sys
 name: sys
- hostPath:
  path: /
 name: roo
```

Dann wird über einen Service ein Endpunkt verfügbar gemacht, auf den Prometheus langfristig zugreifen kann.

#### Prometheus

Prometheus wird mit einem Deployment bereitgestellt. Vor der Bereitstellung von Prometheus muss ihm ausreichende Berechtigungen erteilt werden, damit es auf die notwendigen Endpunkte zugreifen kann, um Metriken zu sammeln. In einem K8s-Cluster mit konfiguriertem RBAC wird dies über ClusterRole/ServiceAccount/ClusterRoleBinding erreicht. Nach Abschluss der Konfiguration authentifiziert sich Prometheus über den ServiceAccount, um auf die benötigten Endpunkte zuzugreifen.

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
 name: prometheus
 labels:
  app.kubernetes.io/name: prometheus
rules:
 - apiGroups: [""]
  resources:
  - nodes
  - nodes/metrics
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
 - nonResourceURLs:
  - "/metrics"
  - "/metrics/cadviror"
  verbs: ["get"]
---
apiVersion: v1
kind: ServiceAccount
metadata:
 name: default
 namespace: monitoring-system
 labels:
  app.kubernetes.io/name: prometheus
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
 name: promtheus
 labels:
  app.kubernetes.io/name: prometheus
roleRef:
 apiGroup: rbac.authorization.k8s.io
 kind: ClusterRole
 name: prometheus