---
"title": "2026年 作業ログ"
"summary": "本稿は、2026年1月22日から24日までの作業ログです。著者は、AIエージェント（opencode、legionmindなど）を用いたソフトウェア開発（legionmind-github-bridge、node-unitの改善など）やシステム設計（マルチエージェントシステム）の日々の実践を詳細に記録しています。ログには、具体的に完了したタスク、遭遇した問題（クラスタセキュリティ、エージェントの知識モデリングなど）、生まれたアイデア（エージェントの自律性向上、評価体系の設計など）、および翌日の計画が含まれています。中心的な論点は、著者がAIエージェントを通じて個人の能力を拡張（スケール）することに注力し、効率的なワークフローとエージェントの評価方法を模索していることです。結論として、エージェントの自律性、コンテキスト知識の提供、個人の精力管理の間のバランスを見出す必要があるとしています。"
"tags":
  - "作業ログ"
  - "AIエージェント"
  - "ソフトウェア開発"
  - "効率管理"
  - "マルチエージェントシステム"
  - "自動化"
  - "個人の生産性"
"date": "2026-01-01"
---

# 目次

1.  [2026年](#org7a37329)
    1.  [2026年01月](#orgdf95c10)
        1.  [2026-01-22](#org46a8ace)
            1.  [本日行ったこと：](#org4842a30)
            2.  [考えたこと：](#orgd3c2dea)
            3.  [明日の予定：](#orgfac9005)
        2.  [2026-01-23](#org53cf87b)
            1.  [本日行ったこと：](#org420a748)
            2.  [考えたこと：](#org003bc35)
            3.  [明日の予定：](#org50de801)
        3.  [2026-01-24](#org5af0a91)
            1.  [本日行ったこと：](#org69bd02c)
            2.  [考えたこと：](#org1f09dca)
            3.  [明日の予定：](#org8a10f91)
        4.  [2026-01-25](#org1d94cd3)
            1.  [本日行ったこと：](#org1ca275c)
            2.  [考えたこと：](#org48ae323)
            3.  [明日の予定：](#org7111e30)
        5.  [2026-01-26](#org43faf05)
            1.  [本日行ったこと：](#org8efa648)
            2.  [考えたこと：](#orga5425d1)
            3.  [明日の予定：](#orge845cbe)
        6.  [2026-01-27](#org3411989)

<a id="org7a37329"></a>

# 2026年

<a id="orgdf95c10"></a>

## 2026年01月

<a id="org46a8ace"></a>

### 2026-01-22

<a id="org4842a30"></a>

#### 本日行ったこと：

1.  opencode-feishu-notifierをリファクタリングしました。これで、決められた方式でユーザーに通知を送信するようになりました。
2.  AIにlegionmind-github-bridgeの開発を続けさせました。opencodeのマルチエージェントモードを使い始め、5つのエージェントを起動して5つの問題を修正させました。一人で2時間もがりがり実行し、5時間分のcodexトークンを消費し尽くしました。
3.  本日、sgクラスタのノードが1台ダウンしました。ログを確認したところ、継続的なSSH試行攻撃を受けていたことが判明し、これは良くありません。簡単に調査し、いくつかの対策案を考えました：
    - パスワード認証を無効化する
    - インターネット全体に対するsshd接続を無効化する
    - クラスタをNATの背後に移動する
4.  いくつかの雑務を処理しました。zlが来週蘇州に来るので、時間をかけて手配しましたが、結果は順調ではありませんでした。これ以上この件に精力を注ぐつもりはありません。

<a id="orgd3c2dea"></a>

#### 考えたこと：

現段階では、私は同時に2〜3つの事柄しかスケジューリングできません。開発作業、日常の手配、思考とアウトプットを含みます。この範囲を超えるとスケジューリングが追いつかず、疲労を感じやすくなります。これは、既に可能な限り作業をAIエージェントに任せている状況です。したがって、以下の2点の改善方向があると考えます：

- コーディングタスクについては、エージェントの自律性を可能な限り高めるべきです。最適化目標は以下の通りです：
  1.  私への干渉をできるだけ少なくする
  2.  できるだけ多くの作業を行わせる
  3.  作業の信頼性を可能な限り向上させる
- 私自身についてもいくつか向上させる必要があります：
  1.  自分の精力を管理し、急速に疲弊しないようにする
  2.  複数の異なるコンテキストで同時に作業する能力を高め、取りこぼしや忘れを防ぎ、進捗管理を行う

上記の考えに基づき、明日は以下の2つの方向で試行できると考えます：

1.  legionmind用のマルチエージェントテンプレートを設計し、opencodeを使ってYuanの何らかのコーディングタスクで実験する
2.  作業ログの記録を続け、精力とコンテキスト管理の方法を模索する。

<a id="orgfac9005"></a>

#### 明日の予定：

1.  前述の通り、マルチエージェントの実験を行う
2.  legionmind-github-bridgeを続ける
3.  時間があれば、クラスタのセキュリティ対策を行う

&#x2014;

全体的に、現在の主軸はAIを使って自分自身をスケールさせ、その後、他者をスケールさせることを試みることです。

<a id="org53cf87b"></a>

### 2026-01-23

本日は少し風邪気味で、頭痛があり、生産性が低かったです。しかし、日々のまとめを始めたことを嬉しく思います。

<a id="org420a748"></a>

#### 本日行ったこと：

1.  AIの助けを借りて、マルチエージェントシステム一式を設計しました。このシステムはまだ体系的な磨きがかけられていません。
2.  legionmind-github-bridgeがまた一歩前進しました。
3.  node-unitのプリエンプション設計と実装を修正しました。以前は、あるnode-unitがfailed状態になった時、その配下のすべてのdeploymentがクリアされていましたが、現在は一つずつクリアされるようになりました。
4.  先物証券会社の口座開設における中国金融先物取引所の試験を受けました。なんと、試験中はカメラを常時オンにし、最小化や画面切り替えが禁止されていました。幸い、無制限に再試行可能で、これは私には難しくありませんでした。95点の高得点で合格しました。

<a id="org003bc35"></a>

#### 考えたこと：

私の目標は、可能な限り少ない摩擦でエージェントの自律を実現することです。現在の私のワークフローは以下の通りです：

1.  legionmindは開発作業のSOPとして機能し、それはエージェントスキルです。私はエージェントスキルが好きです。
2.  opencodeはエージェントの実体として機能し、私はそのbash / tool calling / langraph / command / subagentなどの機能を使用しています。もし将来opencodeを捨てる日が来たら、これらが私の実装待ちリストになります。
3.  現在少し頭を悩ませているのは、スキルとこれらのサブエージェントをどのように組み合わせるかです。

一日中頭痛に悩まされ、夜になってようやく少し頭がすっきりしました。一日の終わりにこれらの考えを書くのは良い方法ではないかもしれません。事実のみを記録し、翌朝目覚めた時に考えをまとめるべきかもしれません。

<a id="org50de801"></a>

#### 明日の予定：

1.  このマルチエージェントシステムを利用して何かを行い、gateの資産管理口座を接続してみましょう
2.  legionmind-github-bridgeを続ける
3.  クラスタのセキュリティ対策（時間があれば）
4.  作業時間の計測を再開する。（重要）
5.  明日はsyの友人が来客する予定なので、作業時間が奪われる可能性があります

<a id="org5af0a91"></a>

### 2026-01-24

本日は11時までぐっすり眠り、とてもリフレッシュしました。久しぶりにこんなに思い切り眠りました。

<a id="org69bd02c"></a>

#### 本日行ったこと：

1.  node-unitの新バージョンをリリースしました。比較的安心してリリースできた理由は、詳細なエンドツーエンドテストがあるからです。具体的には、dockerでtimescaledb（postgresql17）を起動し、2つのnode-unitを起動し、データベースに21個の`@yuants/portal`を挿入してテストしました。最終的には半々の状態に収束しました。

    このテストは、所有者のいないdeploymentが大量に出現した時に、2つのnode-unitが起動すると、deploymentの奪い合いが観測できることをほぼテストできます。本当に足りない点は、実際にCPU/メモリを占有するワークロードと、node-unitが何らかの理由でダウンするシナリオです。

2.  新しいマルチエージェント版のlegionmindを使用して、Yuanにおいてvendor-gateのearn口座から口座フローを出力する問題を解決しました。まずエージェントにlegionを使ってドキュメントを作成させ、以下のように多くのドキュメントを出力しました：

        .legion/tasks/vendor-gate
        ├── context.md
        ├── docs
        │   ├── api-doc.md
        │   ├── pr-body.md
        │   ├── report-walkthrough.md
        │   ├── rfc.md
        │   ├── spec-bench.md
        │   ├── spec-dev.md
        │   ├── spec-obs.md
        │   └── spec-test.md
        ├── plan.md
        └── tasks.md

    まともなワークフローになったと感じます。しかし、私の新しいマルチエージェントシステムと既存のlegionmindのドキュメント作成にはいくつかの衝突があります。各事柄の境界を慎重に考慮すべきです。例えば、各種ドキュメントの書き方の規範は、いくつかの独立したスキルに分離すべきで、legionmindはワークフローの説明であるべきです。各種エージェントは、自分の作業を完了するために、いくつかの小さなスキルをロードできるべきです。

    もう一つの問題点は、最初の作業でエラーを犯し、口座フローを`account-actions-with-credential.ts`に出力してしまったことです。これは、私がearn口座の接続を完了するためにvendor-okxを参考にするよう要求したからです。このように要求した理由は、現在okxのearn口座のみがaccountとして接続されているからです。しかし、AIはその中にあるいくつかの古い実践も学んでしまいました。現在のexchange接続標準は、すべての口座を`provideExchangeServices`で公開し、`provideAccountActionsWithCredential`を使って口座を接続するのではありません。

    これらの知識は、新しいAIエージェントには備わっていません。このような知識をどのようにモデリングすべきでしょうか？AIエージェントにこのようなプロジェクトコンテキストを外部脳としてどのように提供すべきでしょうか？これは深く考える価値のある問題で、明日は慎重に考える必要があります。

3.  午後はsyの友人たちをもてなすために料理をし、とても疲れました。明日も仕事を続けましょう〜

<a id="org1f09dca"></a>

#### 考えたこと：

- 上記のように、AIエージェントのためにコンパクトな外部脳を設計する方法を慎重に考慮する必要があります。最も単純な方法は、一連のAGENT.mdから始めることです。以前試したことがありますが、これらのドキュメント自体をメンテナンスするオーバーヘッドもかなり高く、ゴミと本当に記録する価値のある経験を区別するのは難しい問題です。現時点では、記憶は他のプロンプトと同じで、エージェント自身が記憶を更新するためのループを持っているだけかもしれません。最も重要なのは、AIエージェントの作業結果をどのように評価するかです。

- 上記に関連して、ある記事が非常に興味深いと感じました。私の言葉で要約してみます：まず、エージェントの一歩の作業の評価について、この評価は以下のいくつかのカテゴリーに分けられます：
  1.  静的ツール評価：コンパイラ、リンター、単体テスト、エンドツーエンドテスト
  2.  モデル評価：別のLLMを使って、私たちが定義したプロンプトに基づいて判断する
  3.  人的評価：私が判断する

  次に、エージェントの体系的な評価には2種類あります：
  1.  能力型：このエージェントは何ができるか？また、成功率が低い可能性があります。例えば、legionを使ってより大きく、より難しいタスクを段階的に実行し、新しい境界を探るような感じです。
  2.  回帰型：以前できた能力をまだ保持しているか？例えば、いくつかのタスクを繰り返しテストし、安定して実現できることを保証します。

  新しい能力が導入された後は、能力型から回帰型に移行すべきです。

  この記事は、`pass@K`と`pass^K`という2つの重要な指標も挙げています。
  - pass@k：k回の試行で少なくとも1回成功する。試行回数が多いほど、少なくとも1回成功する確率が高くなります。適用：「少なくとも1つの利用可能な解を見つける」ことだけを気にするシナリオ
  - pass^k：k回の試行すべてが成功しなければならない。試行回数が多いほど、一貫性を維持するのが難しくなります。適用：ユーザーが毎回信頼性の高いエージェントを期待する場合

  FYI: [この記事を参照](https://medium.com/ai-software-engineer/anthropic-new-guide-shows-how-to-build-quality-ai-agents-without-getting-fooled-29f378ec2609)

- 精力はまだ少し足りません。午後少し作業し、夜に料理をしただけで少し疲れを感じました。いつになったらCZのように眠らなくて済むのでしょうか？

<a id="org8a10f91"></a>

#### 明日の予定：

1.  この評価エージェントのモデルについて考え、このマルチエージェントシステムの反復を続ける。
2.  クラスタのセキュリティ問題。必ずやる。
3.  legion-github-bridge

<a id="org1d94cd3"></a>

### 2026-01-25

本日は散髪に行き、戻ってきたらシステムが不安定になっていることに気づきました。結果的に、ジーゲがterminal_idが同じサービスを2つ起動し、互いに奪い合ったために大きな問題が発生していました。

<a id="org1ca275c"></a>

#### 本日行ったこと：

1.  クラスタをNATの背後に移行しようと試みました。もちろん、全く新しいlegionを使ってこの作業を行いました。私の操作は以下の通りです：
    - まずkopsクラスタを修正し、新しいVPCを作成しました。172.21.0.0/24と172.21.1.0/24のネットワークセグメントを使用しました。そして、トラフィック出口用にNATを作成しました。

      当初は10.0で始まるネットワークセグメントを使用する予定でしたが、試したところAWSがこのようなCIDRの作成を許可しないことが判明したため、172.21で始まるネットワークセグメントに変更しました。ここには落とし穴があり、クラスタリソースで既存のロードバランサーを対応するVPC（元々は暗黙的にデフォルトで指定されていましたが、現在はCIDRが増えたため手動で指定する必要があります）に向ける必要がありました。

    - 次に、新しいインスタンスグループを作成し、新しいVPCを指すようにしました。途中、新しいIGにS3権限がないという小さな出来事がありましたが、手動で追加した後、ノードは正常にクラスタに参加しました。
    - 次のステップは、サービスを新しいIGに手動で移行することです。
    - 最後に、既存のIGを停止します。

    完了した後、クラスタの出口トラフィックが1つのIPのみになっていることに気づき、IPレート制限サービスが少し混乱してしまいました。仕方なくロールバックし、次のステップに進む前にHTTPプロキシのスキルを習得する必要があります。

2.  マルチエージェントは、midasの純資産を自動更新するスクリプトの実践に使用されました。deepseekががりがり長い間書いていましたが、私はかなり満足しています。ここでの核心的な問題は、設計の初期段階で私が気づかなかったエラーがあると、膨大なトークンと時間の浪費が待っていることです。なぜなら、エージェントの作業はそれほど速くないと感じるからです。

    現在、これらのコーディングエージェントはまだかなり原始的で、ネットワークなどの問題で頻繁に終了やクラッシュが発生します。真剣な長時間実行作業を完了させるには、SLI（サービスレベル指標）がまだ少し低いです。これはまた、機会でもあるかもしれません。簡単に考えると、これはソフトウェアエンジニアリングの高可用性などの知識を使って作業する必要があります。

<a id="org48ae323"></a>

#### 考えたこと：

本日は考えが少なく、すべて上記の章にインラインで書きました。

<a id="org7111e30"></a>

#### 明日の予定：

1.  YuanのHTTPプロキシメカニズムを設計する。
2.  リリース後、クラスタを再度移行する

<a id="org43faf05"></a>

### 2026-01-26

本日は自制の一日でした。私は25歳以降、感情に対して明らかな進歩を遂げたことに気づきました。それは、感情の外側に、明らかに理性がコパイロットとして存在するようになったことです。この理性は、感情という巨大な反応炉の中に制御棒を設置します。この制御棒がなければ感情は制御不能になり、自己増殖的な連鎖反応を引き起こし、取り返しのつかない結果をもたらす可能性があります。この制御棒の働きにより、私は何を言うべきか、何を言うべきでないか、何をすべきか、何をすべきでないか、どの決定をすべきか、どの決定をすべきでないかを理解し始めました。これは私の中で起こった喜ばしい変化です。

<a id="org8efa648"></a>

#### 本日行ったこと：

1.  本日はlegionを使ってYuanのHTTPプロキシの設計と実装を行いました。使ってみるとかなりスムーズだと感じました。途中、その設計をレビューし、ある点（利用可能なターミナルを選択する方法）を修正した後、エージェントに任せて一気に進めました。効果は非常に良かったです。
2.  また、legionを使ってmidasの自動更新も行いました。しかし、AIは常にうまくできず、私の要求を正しく理解できず、`@yuants/protocol`の使い方を正しく理解できませんでした。私はいくつかの疑わしい方向があります：AIの知能が足りない（deepseekはまだあまり賢くないかもしれない）、レビューが十分に厳密でない、またはドキュメント知識ベースが十分に厳密でない。
3.  夜中にアラートで起こされました。ホストが原因不明でダウンし、CPU使用率のピークによりホストが自己回復できない状態に入ったようです。ホストのログはひどいもので、私の評価は：アラートは役に立つが、ログはクソだ。メモしておこう！

<a id="orga5425d1"></a>

#### 考えたこと：

1.  入浴中に、現在の私とAIの協力の最も重要な点について考えました。一つはAIエージェント自体のサービス可用性で、実行中に突然終了したりしないことです。ちなみに、ralph loopも基本的には強引な再試行を繰り返すことで可用性を高めています。もう一つの点は、私がAIからの出力をどのように受け入れるかです。例えば、部下から上司への報告でさえ、PPTや専門的な中間管理職という「高価な伝声筒」が必要です。AIから人間への報告が、平らなMarkdownやコードだけに限定されるべきでしょうか？AIのレポートは、各項目に成果物へのリンクを貼ることはできないでしょうか？この部分を専門に担当する引用エージェントはできないでしょうか？

    しかし、現在の私のAIの使い方は、コーディングタスクに集中しているという点で限定的です。

2.  なぜ私がすでにマルチエージェントシステムを持っているのに、このシステムが確実に溝に落ちる方向に向かっているのかについて、慎重に考えてみましょう。前述の推測では、主に3つの可能性が挙げられています：
    1.  AI自体の知能レベル
    2.  人間のレビューが十分に厳密でない
    3.  知識ベースが十分に詳細でなく、AIが迅速に立ち上がるためのより正確な情報を提供できない

    これらの点を慎重に考えてみましょう。そのうち1は考える必要が全くありません。方向2に努力することは、確かにますます詳細なRFCドキュメントに依存し、後続のステップに十分に正確な方向性を与えることができます。しかし、このような開発方法は、**ウォーターフォール**開発モデルに戻ったかのようです。線形プロセスを通じて作業を完了します：

        要求分析 -> バックエンド設計 -> バックエンド開発 -> フロントエンド開発 -> 結合テスト

    形成要因には、技術的側面と組織・プロセスの側面の2つのレベルがありますが、組織・プロセスの側面が*主要因*です。

    技術的側面は、タスク間に自然に依存関係が存在することです。例えば、フロントエンドはバックエンドがインターフェースを提供するのを待たなければならず、バックエンドは製品のCRDが書かれるのを待たなければなりません。

    人間の組織として、ウォーターフォール開発モデルには、効率が低い、品質リスクが露呈しにくい、柔軟性が低い、チーム間の矛盾などの問題があります。私とAIの協力方法として、効率とチーム間の矛盾は、AIの世界には自然に存在しません。あたかも私とAIが異なる時間次元に住む実体であり、私の一日はAIにとって一年のように感じられます。効率が低いとトークンが少し余計にかかるかもしれませんが、これは現在私が最も注目している問題ではありません。私が実際に直面している問題は、要求や事実の理解誤りによる品質リスクであり、柔軟性も低いです。

    私は、AIの能力を最大限に活用しながら、自分自身を最大限に解放する方法を考え出さなければなりません。人間同士が組織化する経験に基づけば、私は指揮系統のより上位のノードになり、AIに安心して仕事を任せながら、レールから外れないようにしなければなりません。

    最も重要な2点：
    1.  意図の整合
    2.  階層化された検証

    この点については、もう少し深く考える必要があります。もっと使って、味わう必要があると感じます。

3.  私は、この「ハンマーを持って釘を探す」状態の悪い側面、つまりパス依存、理解よりも出力を重視することに警戒する必要があります。

<a id="orge845cbe"></a>

#### 明日の予定：

明日はzlが来るので、運動して、食事して、ボードゲームをして遊ぶ予定です。

<a id="org3411989"></a>

### 2026-01-27

zlが来ました。情報量が多く、消化する必要があります。ボードゲームをしました。惨劇ループです。ルールを理解するのに3時間かかり、最後のシナリオで私が悪役の劇作家を演じた時に、このゲームの面白さを感じることができました。最終的には私の完全な勝利でゲームが終了しました。