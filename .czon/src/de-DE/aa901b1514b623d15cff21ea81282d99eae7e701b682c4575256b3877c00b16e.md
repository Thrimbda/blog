---
"title": "Arbeitsprotokoll 2026"
"summary": "Dies ist das Arbeitsprotokoll für den Zeitraum vom 22. bis 24. Januar 2026. Der Autor dokumentiert detailliert seine tägliche Praxis bei der Softwareentwicklung (z.B. legionmind-github-bridge, node-unit-Verbesserungen) und Systemgestaltung (Multi-Agenten-System) unter Verwendung von KI-Agenten (wie opencode, legionmind). Das Protokoll enthält konkret erledigte Aufgaben, aufgetretene Probleme (z.B. Clustersicherheit, Wissensmodellierung für Agenten), entstandene Ideen (z.B. Steigerung der Agentenautonomie, Entwurf eines Bewertungssystems) sowie Pläne für den Folgetag. Die zentrale These ist, dass der Autor daran arbeitet, seine persönlichen Fähigkeiten durch KI-Agenten zu skalieren (scale) und effiziente Arbeitsabläufe sowie Methoden zur Agentenbewertung zu erforschen. Die Schlussfolgerung ist, dass ein Gleichgewicht zwischen Agentenautonomie, Bereitstellung von Kontextwissen und persönlichem Energiemanagement gefunden werden muss."
"tags":
  - "Arbeitsprotokoll"
  - "KI-Agent"
  - "Softwareentwicklung"
  - "Effizienzmanagement"
  - "Multi-Agenten-System"
  - "Automatisierung"
  - "Persönliche Produktivität"
"date": "2026-01-01"
---

# Inhaltsverzeichnis

1.  [2026](#orgf3197da)
    1.  [2026-01 Januar](#orge03e1ca)
        1.  [2026-01-22](#org4d65f86)
            1.  [Was wurde heute gemacht:](#org1006a17)
            2.  [Welche Gedanken gab es:](#orgdb0ae87)
            3.  [Was ist für morgen geplant?](#org750daf2)
        2.  [2026-01-23](#org287b8dd)
            1.  [Was wurde heute gemacht:](#orgf838e08)
            2.  [Welche Gedanken gab es:](#org8998678)
            3.  [Was ist für morgen geplant?](#orgc688fe4)
        3.  [2026-01-24](#org2a15db2)
            1.  [Was wurde heute gemacht:](#orgab0f160)
            2.  [Welche Gedanken gab es:](#org68bf2d9)
            3.  [Was ist für morgen geplant?](#orge3ab04d)

<a id="orgf3197da"></a>

# 2026

<a id="orge03e1ca"></a>

## 2026-01 Januar

<a id="org4d65f86"></a>

### 2026-01-22

<a id="org1006a17"></a>

#### Was wurde heute gemacht:

1.  Das `opencode-feishu-notifier`-Projekt wurde refaktoriert. Es sendet nun Benachrichtigungen an Nutzer nach einem festgelegten Schema.
2.  Die Arbeit am `legionmind-github-bridge` durch den KI-Agenten wurde fortgesetzt. Ich habe den Multi-Agenten-Modus von `opencode` verwendet, der 5 Agenten startete, um 5 Probleme zu bearbeiten. Es lief etwa 2 Stunden lang und verbrauchte dabei meine gesamten 5 Stunden Codex-Tokens.
3.  Ein Knoten im `sg`-Cluster ist heute ausgefallen. Die Logs zeigten, dass er durch wiederholte SSH-Angriffsversuche attackiert wurde. Das ist nicht gut. Nach einer kurzen Prüfung gibt es mehrere mögliche Maßnahmen:
    - Passwortauthentifizierung deaktivieren
    - Den SSH-Zugang für das gesamte Netzwerk schließen
    - Den Cluster hinter einen NAT-Router verschieben
4.  Verschiedene Nebensächlichkeiten wurden erledigt. `zl` kommt nächste Woche nach Suzhou, ich habe etwas Zeit für die Planung aufgewendet, was nicht reibungslos verlief. Ich plane nicht, weitere Energie dafür aufzuwenden.

<a id="orgdb0ae87"></a>

#### Welche Gedanken gab es:

In meiner derzeitigen Phase kann ich nur 2-3 Dinge gleichzeitig koordinieren. Dazu gehören Entwicklungsarbeit, alltägliche Planung, Denken und Output. Überschreite ich diese Grenze, komme ich mit der Koordination nicht mehr nach und ermüde leicht. Und das, obwohl ich bereits versuche, so viel Arbeit wie möglich an KI-Agenten zu delegieren. Daher denke ich, dass es zwei Verbesserungsrichtungen geben sollte:

- Für Codierungsaufgaben sollte ich den Autonomiegrad der Agenten so weit wie möglich erhöhen, mit folgenden Optimierungszielen:
  1.  Sie sollten mich möglichst selten stören.
  2.  Sie sollten möglichst viel arbeiten.
  3.  Die Zuverlässigkeit ihrer Arbeit sollte so hoch wie möglich sein.
- Auch ich selbst muss mich verbessern:
  1.  Meine mentale Energie muss ich besser verwalten, um nicht zu schnell zu ermüden.
  2.  Meine Fähigkeit, in mehreren verschiedenen Kontexten gleichzeitig zu arbeiten, muss ich steigern, um nichts zu vergessen oder zu verlieren, und ich muss den Fortschritt im Blick behalten.

Basierend auf diesen Überlegungen denke ich, dass ich morgen in zwei Richtungen experimentieren könnte:

1.  Für `legionmind` ein Multi-Agenten-Template entwerfen und es mit `opencode` an einer Codierungsaufgabe in `yuan` testen.
2.  Das Führen des Arbeitsprotokolls fortsetzen, um eine Methode für das Management mentaler Energie und Kontexte zu entwickeln.

<a id="org750daf2"></a>

#### Was ist für morgen geplant?

1.  Wie oben erwähnt, ein Experiment mit Multi-Agenten durchführen.
2.  Weiter an `legionmind-github-bridge` arbeiten.
3.  Falls Zeit bleibt, an der Clustersicherheit arbeiten.

&#x2014;

Zusammenfassend ist mein Hauptziel derzeit, mich selbst mit KI zu skalieren und dann zu versuchen, andere zu skalieren.

<a id="org287b8dd"></a>

### 2026-01-23

Ich hatte heute eine leichte Erkältung und Kopfschmerzen, die Produktivität war niedrig. Aber ich freue mich, dass ich mit den täglichen Zusammenfassungen begonnen habe.

<a id="orgf838e08"></a>

#### Was wurde heute gemacht:

1.  Mit Hilfe der KI ein Multi-Agenten-System entworfen. Dieses System ist noch nicht systematisch ausgefeilt.
2.  `legionmind-github-bridge` ist wieder ein Stück vorangekommen.
3.  Das Preemption-Design und die Implementierung von `node-unit` wurden angepasst. Bisher wurden bei einem `failed`-Status eines `node-unit` alle darunter liegenden Deployments gelöscht. Jetzt wird nur noch eins nach dem anderen bereinigt.
4.  Die Prüfung für die Kontoeröffnung bei einem Futures-Broker (CFFEX) abgelegt. Es war überraschend, dass die Kamera die ganze Zeit an sein musste, das Fenster nicht minimiert und der Bildschirm nicht gewechselt werden durfte. Zum Glück gab es unbegrenzte Versuche – das konnte mich nicht aufhalten. Bestanden mit 95 Punkten.

<a id="org8998678"></a>

#### Welche Gedanken gab es:

Mein Ziel ist es, Agentenautonomie mit möglichst geringem Aufwand zu erreichen. Mein aktueller Workflow sieht so aus:

1.  `legionmind` fungiert als SOP (Standard Operating Procedure) für Entwicklungsarbeit. Es ist eine Agenten-Fähigkeit (agent skill). Ich mag agent skills.
2.  `opencode` ist die konkrete Implementierung des Agenten. Ich nutze dessen Fähigkeiten wie bash / tool calling / langraph / command / subagent. Wenn ich `opencode` irgendwann ersetzen müsste, wäre dies meine To-do-Liste.
3.  Was mir derzeit Kopfzerbrechen bereitet, ist, wie ich skills und diese Sub-Agenten kombinieren soll.

Den ganzen Tag Kopfschmerzen, erst am Abend wurde es etwas klarer. Ich stelle fest, dass es vielleicht keine gute Methode ist, diese Gedanken am Ende des Tages aufzuschreiben. Vielleicht sollte ich nur Fakten notieren und die Gedanken erst am nächsten Morgen beim Aufwachen zusammenfassen.

<a id="orgc688fe4"></a>

#### Was ist für morgen geplant?

1.  Mit diesem Multi-Agenten-System etwas Sinnvolles tun, z.B. das Anlegen des `gate`-Anlagekontos.
2.  Weiter an `legionmind-github-bridge` arbeiten.
3.  Clustersicherheit, falls Zeit bleibt.
4.  Wieder mit der Arbeitszeiterfassung beginnen. (Wichtig)
5.  Morgen kommen Freunde von `sy` zu Besuch, daher wird die Arbeitszeit wahrscheinlich knapp.

<a id="org2a15db2"></a>

### 2026-01-24

Heute habe ich mich ausgeschlafen und bin erst um 11 Uhr aufgewacht. Fühlt sich großartig an, so lange habe ich nicht mehr so ausgiebig geschlafen.

<a id="orgab0f160"></a>

#### Was wurde heute gemacht:

1.  Die neue Version von `node-unit` wurde in Betrieb genommen. Der Grund, warum ich sie relativ sorglos deployen konnte, sind meine umfassenden End-to-End-Tests. Konkret: Ein Docker-Container startet eine TimescaleDB (PostgreSQL 17), dann werden zwei `node-unit`-Instanzen gestartet und 21 `@yuants/portal`-Deployments in die Datenbank eingefügt, um zu testen, ob sie sich schließlich gleichmäßig auf beide Instanzen verteilen.

    Dieser Test deckt im Wesentlichen ab, was passiert, wenn eine Reihe herrenloser Deployments auftauchen und zwei `node-unit`-Instanzen online gehen: Man kann beobachten, wie sie abwechselnd Deployments übernehmen. Was noch fehlt, ist eine echte CPU-/Arbeitsspeicher-Auslastung und das Szenario, in dem eine `node-unit`-Instanz ausfällt.

2.  Die neue Multi-Agenten-Version von `legionmind` wurde in `Yuan` eingesetzt, um das Problem der Kontostromausgabe für das `vendor-gate earn`-Konto zu lösen. Ich ließ den Agenten zunächst mit `legion` Dokumentation erstellen. Insgesamt wurden folgende Dokumente erzeugt:

        .legion/tasks/vendor-gate
        ├── context.md
        ├── docs
        │   ├── api-doc.md
        │   ├── pr-body.md
        │   ├── report-walkthrough.md
        │   ├── rfc.md
        │   ├── spec-bench.md
        │   ├── spec-dev.md
        │   ├── spec-obs.md
        │   └── spec-test.md
        ├── plan.md
        └── tasks.md

    Das fühlt sich nach einem soliden Workflow an. Allerdings gibt es Konflikte zwischen meinem neuen Multi-Agenten-System und der bestehenden Dokumentationserstellung von `legionmind`. Ich sollte die Grenzen der verschiedenen Aufgaben genau überdenken. Zum Beispiel sollten Spezifikationen, wie jede Art von Dokument geschrieben werden soll, in separaten skills abgelegt werden, und `legionmind` sollte eine Beschreibung des Arbeitsablaufs sein. Jeder Agent sollte in der Lage sein, einige kleinere skills zu laden, um ihn bei seiner Arbeit zu unterstützen.

    Ein weiteres Problem war, dass er bei der ersten Ausführung einen Fehler machte und den Kontostrom in `account-actions-with-credential.ts` ausgab. Das lag daran, dass ich ihn anwies, sich an `vendor-okx` zu orientieren, um das Earn-Konto zu integrieren. Der Grund für diese Anweisung war, dass derzeit nur das OKX-Earn-Konto ebenfalls als `account` integriert ist. Aber die KI übernahm auch einige veraltete Praktiken daraus. Der aktuelle Standard für die Exchange-Integration ist, alle Konten über `provideExchangeServices` bereitzustellen, nicht über `provideAccountActionsWithCredential`.

    Dieses Wissen besitzt ein brandneuer KI-Agent nicht. Wie sollte solches Wissen modelliert werden? Wie kann ich einem KI-Agenten solchen Projektkontext als externes Gehirn zur Verfügung stellen? Das ist eine Frage, die es zu vertiefen gilt und über die ich morgen genauer nachdenken muss.

3.  Nachmittags habe ich für die Freunde von `sy` gekocht – das hat mich ganz schön erschöpft. Also morgen geht die Arbeit weiter~

<a id="org68bf2d9"></a>

#### Welche Gedanken gab es:

- Wie oben erwähnt, muss ich genau überlegen, wie ich für KI-Agenten ein kompaktes externes Gehirn entwerfen kann. Am einfachsten könnte man mit einer Sammlung von `AGENT.md`-Dateien beginnen. Das habe ich schon versucht, aber der Aufwand für die Pflege dieser Dokumente selbst ist recht hoch. Müll von wirklich wertvollen Erfahrungen zu unterscheiden, ist schwierig. Derzeit scheint es, dass Erinnerungen wie andere Prompts sind, nur dass der Agent möglicherweise eine eigene Schleife hat, um sie zu aktualisieren. Das Wichtigste ist, wie man die Ergebnisse der Arbeit eines KI-Agenten bewertet.

- In Bezug auf den vorherigen Punkt habe ich einen interessanten Artikel gelesen, den ich jetzt in meinen eigenen Worten zusammenfassen möchte: Zunächst kann die Bewertung (Eval) einer einzelnen Agenten-Aktion in mehrere Kategorien unterteilt werden:
  1.  Statische Tool-Eval: Compiler, Linter, Unit-Tests, E2E-Tests
  2.  Model-Eval: Ein anderes LLM bewertet anhand eines von uns definierten Prompts.
  3.  Manuelle Eval: Ich bewerte selbst.

  Dann gibt es zwei Arten der systematischen Bewertung eines Agenten-Systems:
  1.  Fähigkeitsbasiert (Capability): Beantwortet die Frage, was dieser Agent tun kann? Die Erfolgsquote kann niedrig sein, z.B. wenn ich `legion` verwende, um schrittweise größere, schwierigere Aufgaben auszuführen – wie die Erkundung einer neuen Grenze.
  2.  Regressionsbasiert: Kann er seine bisherigen Fähigkeiten weiterhin zuverlässig ausführen? Z.B. durch wiederholtes Testen einiger Aufgaben, um die Stabilität sicherzustellen.

  Wenn eine neue Fähigkeit eingeführt wird, sollte der Übergang von fähigkeitsbasiert zu regressionsbasiert erfolgen.

  Der Artikel erwähnt auch zwei wichtige Metriken: `pass@K` und `pass^K`
  - `pass@k`: Bei k Versuchen mindestens einmal erfolgreich. Je mehr Versuche, desto höher die Wahrscheinlichkeit, mindestens eine brauchbare Lösung zu finden. Anwendbar: Wenn es nur darum geht, "mindestens eine brauchbare Lösung zu finden".
  - `pass^k`: Alle k Versuche müssen erfolgreich sein. Je mehr Versuche, desto schwieriger ist es, Konsistenz aufrechtzuerhalten. Anwendbar: Wenn der Nutzer erwartet, dass der Agent jedes Mal zuverlässig arbeitet.

  FYI: [Siehe diesen Artikel](https://medium.com/ai-software-engineer/anthropic-new-guide-shows-how-to-build-quality-ai-agents-without-getting-fooled-29f378ec2609)

- Meine Energie ist immer noch etwas gering. Nachmittags habe ich ein bisschen gearbeitet, abends gekocht, und schon fühle ich mich müde. Wann werde ich wie CZ sein und nicht schlafen müssen?

<a id="orge3ab04d"></a>

#### Was ist für morgen geplant?

1.  Über das Modell dieses Eval-Agenten nachdenken und das Multi-Agenten-System weiter iterieren.
2.  Das Clustersicherheitsproblem muss angegangen werden.
3.  `legion-github-bridge`